# Probability and Statistics

# Introduction to Probability

## What is Probability?

- **Probability** is a measure of how likely an event is to occur.
- We can calculate the **probability** by dividing the number of favorable outcomes by the total number of possible outcomes.

![Untitled](Images/ProbabilityandStatistics/Untitled%200.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%201.png)

- In probability, an **experiment** is any process that produces an outcome that is uncertain.

![Untitled](Images/ProbabilityandStatistics/Untitled%202.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%203.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%204.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%205.png)

## Complement of Probability

- The **complement** of an event is the probability that the event does not occur.

![Untitled](Images/ProbabilityandStatistics/Untitled%206.png)

- The **complement** rule states that the probability of an event A not occurring is equal to 1 minus the probability of A occurring.

![Untitled](Images/ProbabilityandStatistics/Untitled%207.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%208.png)

## Sum of Probabilities(Disjoint Functions)

- Calculating the sum of probabilities, Considering the Events are **disjoint.**
- **Disjoint events** are events that never occur at the same time. These are also known as **mutually exclusive** events.
- **Disjoint events** are typically represented by the **Union**$(\bigcup)$ .

![Untitled](Images/ProbabilityandStatistics/Untitled%209.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2010.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2011.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2012.png)

## Sum of Probabilities(Joint Functions)

- **Joint events** are events that occur simultaneously or together. In other words, they are events that have outcomes in common.
- **Joint events** are typically represented by the **intersection $(\bigcap)$.**

![Untitled](Images/ProbabilityandStatistics/Untitled%2013.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2014.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2015.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2016.png)

## Independence

- **Independence** happens when the occurrence of one event does not affect the probability of the occurrence of another event.
- When we want the intersection of two events and those events are independent of each other, then it's the **product** of the two **probabilities.**

![Untitled](Images/ProbabilityandStatistics/Untitled%2017.png)

- The **product rule** says probability of A **intersection** B is probability of A times the probability of B, Given that the probabilities are **independent**.

![Untitled](Images/ProbabilityandStatistics/Untitled%2018.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2019.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2020.png)

## Birthday Problem

![Untitled](Images/ProbabilityandStatistics/Untitled%2021.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2022.png)

## Conditional Probability

- **Conditional probability** is about calculating the probability of an event happening given that another event has already happened.

![Untitled](Images/ProbabilityandStatistics/Untitled%2023.png)

- Recall that the **product rule** for **independent** events said that the probability of **A intersection B** is **P(A) * P(B)**. But this only happen when **A** and **B** were **independent**.
- If we have events that are **not independent.** The probability of **A intersection B**, Is the probability of **A** times the probability **B given A.**

![Untitled](Images/ProbabilityandStatistics/Untitled%2024.png)

- So This is the **general product rule.**
- Notice that when events are independent, the **probability of B given A** is the same as **probability of B** because **A** doesn't make any difference on the occurrence of **B.**

![Untitled](Images/ProbabilityandStatistics/Untitled%2025.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2026.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2027.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2028.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2029.png)

## Bayes Theorem - Intuition

- **Bayes theorem** is one of the most important theorems in probability and is used all over the place, including in machine learning. It is used for spam recognition, speech detection, and many other things.

![Untitled](Images/ProbabilityandStatistics/Untitled%2030.png)

- Since this disease happens to one out of every 10,000, If you have a population of 1 million, Then 999,900 are healthy and 100 are sick.

![Untitled](Images/ProbabilityandStatistics/Untitled%2031.png)

- If we test every single person and the test is 99% effective:
    - Among the healthy people it made a mistake in 1% of them which is 9,999.(Healthy people diagnosed as sick)
    - The other 99% of healthy people were correctly diagnosed as healthy.
    - For the sick people it correctly diagnosed 99 people as sick, Since the test is 99% effective.
    - Also it misdiagnosed 1 person as healthy while the person is sick.

![Untitled](Images/ProbabilityandStatistics/Untitled%2032.png)

- We want to figure out the probability that you're sick, given that you were diagnosed sick.
- Since most of the people who diagnosed as sick are mostly healthy, Ypu get a probability of less than 1%

![Untitled](Images/ProbabilityandStatistics/Untitled%2033.png)

- So you get diagnosed sick, but the probability that you’re sick is less than 1%.
- What we saw there is an example of **Bayes Theorem.**

![Untitled](Images/ProbabilityandStatistics/Untitled%2034.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2035.png)

## Bayes Theorem - Mathematical Formula

![Untitled](Images/ProbabilityandStatistics/Untitled%2036.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2037.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2038.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2039.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2040.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2041.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2042.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2043.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2044.png)

## Bayes Theorem - Spam Example

![Untitled](Images/ProbabilityandStatistics/Untitled%2045.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2046.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2047.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2048.png)

## Bayes Theorem - Prior and Posterior

- **Prior** is the original probability that you can calculate, not knowing anything else.
- Then something happens, and that's the event.
- The event gives you information about the probability. With that information, you can calculate something called the **posterior**.

![Untitled](Images/ProbabilityandStatistics/Untitled%2049.png)

- The **posterior** is always a better estimation than the prior because we have that event that gave us information.

![Untitled](Images/ProbabilityandStatistics/Untitled%2050.png)

## Bayes Theorem - The Naive Bayes Model

- What if we want to build a classifier with more than one word, more than one event.

![Untitled](Images/ProbabilityandStatistics/Untitled%2051.png)

- To calculate the probability that an email is spam given the fact that it contains lottery and winning using Bayes theorem.
- you will encounter a problem which is you’d be calculating the number of spam emails that contain the two words divided by the total number of spam emails.
- Say instead we want find spam email with 100 words, So using **Bayes theorem** I need to divide the number of emails that contain all 100 words divided by the number of spam emails.
- However, asking for an email to contain 100 words is very hard. Maybe there's no emails like that in our database, and so we get 0 over 0. And that's not a good calculation.

![Untitled](Images/ProbabilityandStatistics/Untitled%2052.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2053.png)

- The solution is instead of calculating the precise probability, We’re going to estimate it using the **Naive assumption.**
- **Naive assumption** says that the appearances of the words lottery and winning are **independent** from each other.
- This is obviously not true, Words are not independent from each other, But if we assume that they're independent, then the math works out much better.
- If you look at probability of lottery and winning given spam, that's the probability of an intersection of two things, And if they happen to be **independent**, then their probability is the **product** of the two things.

![Untitled](Images/ProbabilityandStatistics/Untitled%2054.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2055.png)

- This can happen with **N words**. **N** can be huge, but the probability of an email containing all these words given that is spam can be estimated as the **product** of all these probabilities of the email containing each one of the words given that it's spam. And that is the **naïve Bayes algorithm**.

![Untitled](Images/ProbabilityandStatistics/Untitled%2056.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2057.png)

## Probability in Machine Learning

- It turns out that machine learning is a lot about probabilities. Many times in machine learning what you want to do is, you want to calculate a probability of something given some other factors.

![Untitled](Images/ProbabilityandStatistics/Untitled%2058.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2059.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2060.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2061.png)

# Probability Distributions

## Random Variables

- Random variables can take many values. For example, the temperature is a random variable that can take many values. Another random variable is the number of heads I obtain if I toss a coin 10 times.
- You can think of X as a variable that not always has the same value.

![Untitled](Images/ProbabilityandStatistics/Untitled%2062.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2063.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2064.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2065.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2066.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2067.png)

## Probability Distributions(Discrete)

- Imagine if we have all the possible scenarios of an event that can happen. Put them on this horizontal axis and for each one of them, look at the probability that they happen. This forms a **probability distribution.**
- These are the probabilities that can be visualized by a histogram.

![Untitled](Images/ProbabilityandStatistics/Untitled%2068.png)

- All discrete random variables can be modeled by their **probability mass function**, also abbreviated as **PMF**.
- It contains all the necessary information to understand how the probability distributes among all the possible values of the variable.

![Untitled](Images/ProbabilityandStatistics/Untitled%2069.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2070.png)

## Binomial Distributions

- The **binomial distribution** is an example of a discrete distributions
- Say we toss a coin 10 times. How many heads can I obtain? It could be from 0 all the way up to 10. Each one comes with its own corresponding probability, so we draw the histogram of probabilities, and that's the **binomial distribution**.
- What is the probability to obtain two heads when you flip five coins?
    - For each flip, there's a 1/2 chance to get heads or tails. If you multiply these together, you get 1/32, which is the probability of this specific outcome.
    - But there are more ways to obtain two heads out of five, Also it has the same probability as the above one.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%2071.png)
    
    - It turns out that there are actually 10 possibilities to get two heads out of five.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%2072.png)
    
    - There are some general way to find the number of possible combinations.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%2073.png)
    
    - This is called the **binomial coefficient**, and it counts the number of ways you can order two heads and three tails.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%2074.png)
    
    - One common property of binomial coefficient is that $\dbinom n k$ is the same as$\dbinom {n} {n-k}$. The reason for this is because obtaining **k** heads is the same thing as obtaining **n-k** tails.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%2075.png)
    
    - Here is a general way to write the **PMF** for the number of heads in **n** coin tosses:
        - We will multiply the probability of seeing **x heads** times probability of seeing **n - x tails,** This is the probability of one particular ordering.
        - To take into account all possible orders which is the **binomial coefficient** $\dbinom n k$
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%2076.png)
        
        - We write the equation like that:
        - The tilde symbol means that the variable X follows the distribution to the right of the expression.
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%2077.png)
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%2078.png)
        
    - If **p** is **0.5** and **n = 5**, then you get the following **PMF**.
    - Notice that since **p** is **1/2**, then the **PMF** is **symmetrical.**
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%2079.png)
        
    - If we have a biased coin say of **p=0.3,** then you have greater chances of seeing a small number of heads, and this is reflected in the **PMF**. ****

![Untitled](Images/ProbabilityandStatistics/Untitled%2080.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2081.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2082.png)

## Binomial coefficient

- Binomial coefficient is the number of ways to obtain **k** elements out of a set of **n** in an **unordered way**.
- So in order to get the binomial coefficient, First we need to get the ordered set of length **k.**

![Untitled](Images/ProbabilityandStatistics/Untitled%2083.png)

- Since we know many of the combinations actually repeat, how many of them repeat?
    - We had that the number of ways of picking **ordered sets of length k** that picked every set many times.
    - **K!** is simply the number of ways of ordering **k** numbers or **k** different objects.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%2084.png)
    
    - So since we want them **unordered**, then we have to divide by **k!**
- That is the expression for $\dbinom n k$ for the binomial coefficient $\dbinom n k$, the number of ways to obtain **k** elements out of a set of **n** in an **unordered** way.

![Untitled](Images/ProbabilityandStatistics/Untitled%2085.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2086.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2087.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2088.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2089.png)

## Bernoulli Distribution

- **Bernoulli** is a very important distribution in probability and statistics, which has one parameter (p), Which is the probability of **success**.

![Untitled](Images/ProbabilityandStatistics/Untitled%2090.png)

## Probability distributions(Continuous)

- When your events are a list, you have a **discrete distribution**. And when your events are an **interval**, you have a **continuous distribution.**
- So with a continuous problem instead of asking what is the probability at specific time, You should ask what's the probability between a certain window time.

![Untitled](Images/ProbabilityandStatistics/Untitled%2091.png)

- This is how a continuous distribution looks like, It is just a bunch of very, very skinny bars, infinitely many of them, that become just a curve.

![Untitled](Images/ProbabilityandStatistics/Untitled%2092.png)

## Probability Density Function

- **Discrete distributions** have a **probability mass function**, on the other hand, **Continuous distributions** have a **probability density function.**
- In **discrete distributions** probabilities responds to **height**, the more the height the more the probability.
- In **continuous distributions** probabilities respond to areas, the thicker the interval, the more probability it is.

![Untitled](Images/ProbabilityandStatistics/Untitled%2093.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2094.png)

- If we want the probability of calls at exactly 2 minutes, then we'll be talking about the area of this segment over here, that is a line segment, and it has no area. So, that's why we say that that probability is 0.

![Untitled](Images/ProbabilityandStatistics/Untitled%2095.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2096.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%2097.png)

## Cumulative Distribution Function

- In **continuous distribution** you have to calculate areas underneath a curve in order to find the probability that a call is between, let's say, two and three minutes.
- The **cumulative distribution** function  shows the actual probability that the call is between zero and a certain number of minutes.
- In order to get **cumulative distribution**, we need to get the **cumulative probability,** and it's this red curve over here. Notice that it always starts at zero and the value at the very right is one.

![Untitled](Images/ProbabilityandStatistics/Untitled%2098.png)

- For continuous distributions, You go over the PDF from the beginning until the end and you simply add up the pieces to create the CDF curve.
- In the graph below, This is a particular case where the curve starts and ends at finite points.
- The blue curve in the left, the density function could go infinitely to the left or infinitely to the right, in which case, so does the other curve, and that means that it has a **limit of zero** to the **left** and a **limit of one** to the **right**.

![Untitled](Images/ProbabilityandStatistics/Untitled%2099.png)

- These two curves give us the same information except written different. On the **left**, we have to calculate **areas** to find probabilities, and on the **right**, we simply have to look at **heights**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20100.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20101.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20102.png)

## Uniform Distribution

- **Uniform distributions** are probability distributions with equally likely outcomes.

![Untitled](Images/ProbabilityandStatistics/Untitled%20103.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20104.png)

- If you look at the histogram, it seems that one of the bars is slightly taller than the rest however, this is just based on measurements so some deviation is expected.
- Since, any value between 0 and 15 have the same frequency, The pdf must be constant, meaning the height of every interval must be equal, and the height is equal 1 / 15 = 0.06
- In a **discrete uniform distribution**, outcomes are discrete and have the same probability.

![Untitled](Images/ProbabilityandStatistics/Untitled%20105.png)

- In a continuous uniform distribution, outcomes are continuous and infinite.

![Untitled](Images/ProbabilityandStatistics/Untitled%20106.png)

- When interval **a, b** is big the **height** of the **PDF** is **small**, and the **height** it quickly increases as the **interval** gets **short**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20107.png)

- For the general uniform distribution between a and b, you can see that
- The **CDF** is the ratio $\frac {x-a} {b-a}$ for $a \leq x < b$
- If **x** $\leq$  **a**, you have **0** cumulative probability.
- For **x** bigger than **b**, you've gathered all the probability, So the CDF is **1** after that point.

![Untitled](Images/ProbabilityandStatistics/Untitled%20108.png)

## Normal Distribution

- The **normal distribution**, also named **Gaussian distribution.**
- If we take a **binomial distribution** with a large number of **n** and plot it, it will look like a **bell curve**, That **bell curve**  is called the **normal distribution.**
- This means that when **n** is very **large**, the **binomial distribution** can be approximated by a **Gaussian distribution.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20109.png)

- If we have a binomial distribution data that looks like a bell curve, and we want to fit a normal distribution to it:
    - First, We're going to try to fit it with this curve.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20110.png)
    
    - Then, look at where the blue data is centered, That’s the mean $\mu$. By subtracting the mean of the blue data from the orange curve, it will be centered.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20111.png)
    
    - Then, We need to widen the orange curve to fit the blue data by dividing the orange curve with the blue data **standard deviation $\sigma$ ,** The standard deviation tells us how thick the curve is.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20112.png)
    
    - Then, We need to adjust the height of the orange curve, we need to divide by the area of the orange curve to better fit the blue curve.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20113.png)
    
    - Now it fits very well, That is the formula for gaussian or normal distribution.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20114.png)
    
- **Normal Distribution** formula:

![Untitled](Images/ProbabilityandStatistics/Untitled%20115.png)

- The **normal distribution probability density function** is always positive, although it's very small for big and for negative big numbers.

![Untitled](Images/ProbabilityandStatistics/Untitled%20116.png)

- If you have a random variable **X** with a **probability density function**, you can write it like this:
    - $\mathcal{N}$ stands for **normal** and $\sigma^2$ is the **variance.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20117.png)

- How to **standardize** any **normal distribution?**

![Untitled](Images/ProbabilityandStatistics/Untitled%20118.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20119.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20120.png)

## Chi-Squared Distribution $x^2$

- Let’s say You send the message 10010 through communication channel. The channel has noise which will affect the message you send.
- you receive the message 10010 plus some **noise** that affected the signal, and let's call the noise **Z,** which has a **random** nature.

![Untitled](Images/ProbabilityandStatistics/Untitled%20121.png)

- One common assumption in communications, and the **noise Z** has a **Gaussian distribution** with **mean** equals **0**
- One measure that is very useful in communications is the **noise power**, which is roughly modeled by the **square** of the **noise**.
- This measure is important because it is associated with the **variance** or **dispersion** of the **noise** and will determine how hard it is to correctly **interpret** the received signal.

![Untitled](Images/ProbabilityandStatistics/Untitled%20122.png)

- In order to get the distribution of **W,** we're going to assume that **Z** follows a **standard normal distribution** with parameter **0** and **1.**
- Each value of **W** can be achieved with two different values of **Z**, which are $- \sqrt[2] {w}$ and $\sqrt [2] {w}$.
- The probability that W $\leq w$ is the **area** under the **PDF curve** on the Gaussian between these two numbers.
- You can get the **CDF** for **W** by finding these **areas** for each possible value **W**.
- Notice that for small values of **W**, you gain area at a much quicker rate. This is because the **Gaussian distribution** concentrates **probability** around **0**.
- This is known as the **Chi-squared distribution** with **one** **degree** of **freedom**

![Untitled](Images/ProbabilityandStatistics/Untitled%20123.png)

- Since the **CDF** is the **integral** of the **PDF**, Then you can easily find the **PDF** by taking the **derivative** of the **CDF**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20124.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20125.png)

## Sampling from a Distribution

- let’s say you have a data set, for example, and you need it to be larger, but you can't go and collect more data, it's too expensive.
- So what can we do? we can create some **synthetic** data that looks a lot like the original one.
- A way to do this is to **construct a distribution** out of this data, and then **sample** out of it. And by **sampling** I mean picking points that have the probabilities given by the original distribution.
- As you know, the **probabilities** of the **outcomes** add to one, So you can **stack** them up together, Then do the following steps to pick random colors with the probabilities given in this graph:

![Untitled](Images/ProbabilityandStatistics/Untitled%20126.png)

- Another way to solve this problem, Create another plot here where we simply rotate at the bars, Push them to the right and draw that **red line**, which is actually the **cumulative distribution function**.
- Now all you have to do is you **sample uniformly** from the **vertical interval,** Then read out what the value is in the horizontal **axis** of the **cumulative distribution function.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20127.png)

- We can also do this for a continuous distribution, Let's say, the **Gaussian distribution** on the left.
- Picking randomly from the distribution is not easy because calculating areas is hard.
- But if we take a look at the **CDF** on the right and then pick **uniformly** from that gray interval, the interval from 0 to 1, that's vertical.
- Then take a look at where this hits the distribution and where it hits the **horizontal axis**.
- So this points over here are actually distributed based on the **normal distribution** on the left.
- So the **CDF**, both for the **discrete** and the **continuous case**, is a very useful method when you want to **sample** from a particular distribution.

![Untitled](Images/ProbabilityandStatistics/Untitled%20128.png)

# Describing Distributions

## Expected Value

- The **mean** has another more formal name for it used in probability called **expected value.**
- The equation below written this way is the **weighted average** of the values of the variable where the weights are the probabilities of each possible value.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/d250b10f-6ab9-416a-af02-9d3f6db49800/Untitled.png)

- In general, if you have a discrete random variable **X**, it will have a probability mass function that provides the probability of each possible **X** can take.
- The **expected value** will be **X** times the probability of **X** summed over all possible values of X.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/07f29093-b656-439c-a1df-8223963c9651/Untitled.png)

- Since we're performing a **weighted average** of the values the variable can take, if every value on your data has the same probability or mass, then the **expected value** will be right in the middle.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/561fa75e-7943-49de-9e97-05562a7cfaef/Untitled.png)

- In both cases, you are summing up all the possible values of X, but in the **discrete case** you weight the sum using the **probability mass function**, and in the **continuous case** you are using the **probability density function**.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/acd749c5-fc95-4013-b9d7-bcde1a6552e8/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/43927810-769f-4fd8-884b-a28aa6d3afb4/Untitled.png)

- There's a common misconception, The mean doesn’t generally split the data in half

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/d3d49cb4-85a9-40f0-bb22-a7e5986209aa/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/c73e9fa1-1afc-41ca-bdef-acab3e02d4d4/Untitled.png)

## Other Measures of Central Tendency: Median and Mode

- The **mean** is not the only way to measure the center of a distribution, There are other ways to measure what are the central or typical values for a probability distribution.
- the **average** here is a little **deceiving.**

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/1b91dc0f-8935-468c-8872-e85f3f4e8d24/Untitled.png)

- Michael Jordan’s salary tips the scale So he brings the average up for everybody and the average is no longer measuring what the average student makes. It got skewed by that one point on the right.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/2f486667-9c61-4385-a43f-55a9b71c9030/Untitled.png)

- To fix this problem we can consider a different metric. Put all salaries in order. So now it's just the position that matters then we can pick the number in the very middle. so the salary in the very **middle** is the **median.**

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/cae94a1b-af6e-4724-9b4c-5c3a9a61b291/Untitled.png)

- If you have an even number of points, then you simply take the average of the two points in the middle.
- So the moral here is when the **average** is **deceiving**, go for the **median** and you may get a better idea of your data.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/3e340703-649d-4214-a4aa-9bda6af3ddbf/Untitled.png)

- Another way to describe the center of a distribution is called the **mode**.
- Mode is  the value at which the **distribution** has the **highest probability**, which makes it the most frequent one.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/adadc0cf-3f5a-4f3b-8c7e-0d6e4f5d6085/Untitled.png)

- The mode in a **discrete distribution** is the point where the tower is the **highest** and for a **continuous distribution** the **mode** is simply the value that has the **highest height**.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/9288e505-0c0d-4cff-9b47-fb09d789b7fc/Untitled.png)

- The **mode** may not be unique as in a **distribution** where the **maximum** value gets repeated many times and that's called a **multimodal distribution**. And in places like the **uniform distribution**, for example, everything is a **mode**.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/1e10794d-d86b-41bb-8169-727e9aa27d7a/Untitled.png)

## Expected Value of a Function

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/ed095397-dcac-415d-8e0f-7bf55ea170a7/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/f5a7b145-c8dd-4334-a3bb-db3d233293a6/Untitled.png)

## Sum of Expectations

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/0cf18700-7a5d-4190-aed6-6d80c22cb870/Untitled.png)

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/8922aaf7-be84-4ccc-8d4e-ef3a7243439a/362a1eda-25e3-429c-924a-5228b2d386a7/Untitled.png)

## Variance

- It turns out that expected value doesn't tell us the whole story about the distribution.
- For example, two distributions may have the same expected value, but one of them can be very narrow and the other one can be very wide. This is captured by something called the **variance**

![Untitled](Images/ProbabilityandStatistics/Untitled%20129.png)

- One way to think of the idea of spread is how far away the points are from the expected outcome.
- If the spread is small, you would expect most points to be close to the expected value. With a bigger spread, you would expect most of the points to be farther away.

![Untitled](Images/ProbabilityandStatistics/Untitled%20130.png)

- The preferred method of measuring **spread** is to actually **square** the **deviations**.
- Using **squared deviation** All of the values will now be **positive**, which is what the **absolute deviation** attempted to do, but without introducing some of the mathematical issues of the **absolute value function**.
- Then you can calculate the **variance** using the **expected squared deviation.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20131.png)

- The **Variance** Formula contains four steps:
- Notice, This is just like **expected value**, that this is a **weighted average**. In these examples, all the outcomes had equal probability. But if they didn't, you would use the probability of each outcome as weights.

![Untitled](Images/ProbabilityandStatistics/Untitled%20132.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20133.png)

- **Variance** has an alternative formula:

![Untitled](Images/ProbabilityandStatistics/Untitled%20134.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20135.png)

- **Adding** a number to a random variable just changes the point the new distribution is centered around, but it doesn't impact the spread.
- **Multiplying** x by a value, however, will impact the spread of your data.

![Untitled](Images/ProbabilityandStatistics/Untitled%20136.png)

## Standard Deviation

- The **variance** is a pretty useful way to measure the **spread of a distribution**. However, it has one small drawback, the **units.**
- We can take the **square root of the variance**, we call that the **standard deviation**.
- **Standard deviation** is a pretty useful way to measure the **spread of a distribution** using the same **units** of the **distribution**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20137.png)

- In the **normal distribution**, the **standard deviation** is very useful.
- A good visual cue to determine the value of **sigma** is where the bell starts changing concavity.
- In statistics, it's very common to talk about being within 1 or 2 or 3 standard deviations of the mean when you're talking about a normal distribution.

![Untitled](Images/ProbabilityandStatistics/Untitled%20138.png)

## Sum of Gaussians

- How to add two **gaussian distributions**?
    - Suppose you can model the **processing time** with a Gaussian distribution with mean 10 and standard deviation 2 and The total latency as Gaussian with mean 5 and standard deviation 1, and suppose also that these two variables are independent of each other.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20139.png)
    
    - Get the corresponding densities for the processing time and for the latency.
    - Then sample each variable 10,000 times and draw the resulting histograms. They both fit the curves pretty well.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20140.png)
    
    - With these samples, you can now generate 10,000 samples off the response time.
    - Notice that R is still **Gaussian**. We need to calculate the parameters of this **Gaussian.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20141.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20142.png)
    
    - Now in general, if you have a linear combination of variables where X and Y are both **Gaussian** and both of them are **independent**, then the resulting variable follows a **Gaussian distribution**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20143.png)
    

## Standardizing a Distribution

- When you have a distribution with **mean** $\mu$, it's always nicer when the distribution has **mean 0**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20144.png)

- Why is it that the new variable $x - \mu$ has **expectation 0**?

![Untitled](Images/ProbabilityandStatistics/Untitled%20145.png)

- In the same way that we want the **mean** to be **0** we want the **standard deviation** to be **1**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20146.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20147.png)

- **Standardizing** a **distribution** has several benefits:
    - Firstly, it transforms datasets into a standard scale, making it easier to compare between different datasets.
    - Secondly, it simplifies statistical analysis, particularly when using techniques that assume a standard normal distribution.
    - Finally, standardizing features in machine learning can improve the convergence rate of optimization algorithms and prevent some features from dominating others, leading to improved model performance.

![Untitled](Images/ProbabilityandStatistics/Untitled%20148.png)

## Skewness and Kurtosis: Moments of a Distribution

- The **expected value** and the **variance** or **standard deviation** paint a really good picture of the distribution.
- However, there are a lot of subtleties that are not captured by them. Some of them are called **skewness** and **kurtosis.**
- Before we get into other ways to measure distribution, We need to know about the **moments**.
- $E[X]$ is the first moment,  $E[X^2]$ is the second moment, etc..

![Untitled](Images/ProbabilityandStatistics/Untitled%20149.png)

## Skewness and Kurtosis - Skewness

- If you look at these two games, they are the exact opposite.

![Untitled](Images/ProbabilityandStatistics/Untitled%20150.png)

- As you can see, these two games are tremendously different.
- Let's see if that difference can be detected by either the **expected value** or the **variance**.
- The **expected value** of these two games is the same, Also the **variance** of these two games is the same but they're vastly different games.

![Untitled](Images/ProbabilityandStatistics/Untitled%20151.png)

- seems like these two distributions have the same first moment and the same second moment.

![Untitled](Images/ProbabilityandStatistics/Untitled%20152.png)

- In order to tell them apart, We're going to use the **third moment**, the **expected value** of the **cube of the variable**.
- The **cube** of the **variable** detects if you have numbers that are **skewed** towards the **right** or **skewed** towards the **left**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20153.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20154.png)

- **Skewness** is the **expected value** of the **centered** and **standardized distribution cubed**.
- **Skewness** is a measure of the asymmetry of a distribution. A distribution is asymmetrical when its left and right side are not mirror images. A distribution can have right (or positive), left (or negative), or zero skewness.

![Untitled](Images/ProbabilityandStatistics/Untitled%20155.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20156.png)

## Skewness and Kurtosis - Kurtosis

- which game is riskier?
- The game 2 seems a lot more conservative with the $0.10. But once you throw in the $10, it becomes a little riskier, but the probability that you win $10 is very small, or that you lose $10.

![Untitled](Images/ProbabilityandStatistics/Untitled%20157.png)

- These two games have the exact same **variance**. Neither one of them is riskier than the other one.
- They also have the same **expected value** and **skewness**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20158.png)

- So in order to describe to someone that these 2 games are different, We should go for the **fourth moment.**
- It turns out when the **distribution** has very large numbers very far away from the center, even if their probabilities are tiny, $E[X^4]$ captures this.

![Untitled](Images/ProbabilityandStatistics/Untitled%20159.png)

- **kurtosis** is the **expected value** of $x- \mu$ divided by $\sigma$  raised to the 4 power.
- **Kurtosis** is a descriptive statistic used to help measure how data disperse between a distribution's center and tails, with larger values indicating a data distribution may have “heavy” tails that are thickly concentrated with observations.

![Untitled](Images/ProbabilityandStatistics/Untitled%20160.png)

- what does kurtosis say of a distribution?
    - If the tails are very **skinny**, the **kurtosis** is **small**.
    - If the tails are **thicker**, then we have a **large kurtosis**.
- Even if they have the same variance, the variance may still not be able to pick up. Because even if you have thick tails, you may have a very skinny distribution in the middle. But kurtosis is a much more sensitive measure for the thickness of the tails of the distribution.

![Untitled](Images/ProbabilityandStatistics/Untitled%20161.png)

- We’ve learned many ways to tell distributions apart **expected value**, **Variance, standard deviation**, **skewness**, and **kurtosis**. With these four tools, you'll be able to say a lot about your **probability distributions**.

## Quantiles and Box-plots

![Untitled](Images/ProbabilityandStatistics/Untitled%20162.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20163.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20164.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20165.png)

## Visualizing Data: Box-plots

- There's a visualization called the **box plot** or the **box and whiskers plot**, which is a standardized way of displaying the distribution of your data based on five statistics the **minimum**, the **maximum**, the **median**, the **first quartile**, and the **third quartile**.
- The **interquartile range** $Q3- Q1$ is  where 50% of your data lies.

![Untitled](Images/ProbabilityandStatistics/Untitled%20166.png)

- Note that to draw the **whiskers**. You draw two lines going from the end of the box until       $Q1 - 1.5  * IQR$ and one going from $Q3 + 1.5 * IQR$.
- The **whiskers** should never go beyond the **max** and the **minimum** values of the data set. So if that happens, like in this example, simply cut the whisker at those values.

![Untitled](Images/ProbabilityandStatistics/Untitled%20167.png)

- The **box plot** is very useful, You can get plenty of insight on your data.
- In this case, you can easily see that the data is skewed because $Q3-Q2$  is way bigger than $Q2-Q1$.
- For this small case, we can see that there are no extreme points or **outliers** since both **whiskers** end at the **max** and min values. If there are any values that are **outside** of the **whiskers**, then we say that those are **outliers**, they're too far from the center.
- the length of the **box** and the **whiskers** allow you to analyze the **dispersion** of the data.

![Untitled](Images/ProbabilityandStatistics/Untitled%20168.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20169.png)

## Visualizing Data: Kernel Density Estimation

- All these samples seem to come from a continuous random variable. You know that you can describe your **data distribution** for **continuous** variables with the **probability density(PDF**).

![Untitled](Images/ProbabilityandStatistics/Untitled%20170.png)

- Can we get how **PDF** looks like from this data?
    - Plot a **histogram** of the dataset because a **histogram** satisfies all the conditions of a density function.
        - It's **positive** and the **area under the curve** is **one**.
        - However, It's not a great approximation because:
            - **PDFs** are usually a **smooth** function
            - Also the **discontinuities** of the bars appear from the technique used to compute histograms and not from the data itself.
            - In other words, the actual distribution where these come from may have a pretty **smooth density function**, but since we're taking a **histogram**, it looks like it has a lot of peaks.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20171.png)
    
    - To approximate the **PDF** of our data from a **histogram** we can use a **kernel density estimation**
    - We start by making our **observations** in a graph. Then you want each point of your dataset to have an effect that spreads around the observation point because we want high density where there's a lot of points and low density where there's no points.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20172.png)
    
    - Draw a **Gaussian curve** on top of each data point. This is called the **kernel**. You could choose other functions than the **Gaussian**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20173.png)
    
    - The value of **Sigma** you choose for the Gaussian density will determine how far the effect of each point spreads. It could be thin or it could be wide.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20174.png)
    
    - Lastly, all you have to do is **multiply** everything by $1/n$ and **sum** all the blue curves to get **area under the curve** equal one.
    - It Doesn't look so great because you've try to approximate a density from just 12 data points.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20175.png)
    
    - If you try from many points, then you're actually going to get a really nice smooth function that actually resembles the PDF well. This is a way to approximate the PDF based on the data.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20176.png)
    

## Visualizing Data: Violin Plots

- **Violin plots** contains the information of both the **kernel density estimation** and the **box plots**
- All you do is you put the **kernel density estimation** at the side of the **box plot**.
- The **violin plot** looks like you have the **KDE** curve, the **mean,** the **quartiles** and the **whiskers.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20177.png)

## Visualizing Data: QQ Plots

![Untitled](Images/ProbabilityandStatistics/Untitled%20178.png)

- Sometimes a quick inspection of something as simple as a bcan let us know that data is in **Gaussian**.
- For example, the left one doesn't look very **Gaussian**, and the right one looks a little **gaussian**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20179.png)

- To get a more exact answer if the data is **Gaussian** or not, We use **quantile quantile plots     (QQ plots)**.
- This present a graphical comparison between **quantiles** in your data and **quantiles** from a **normal distribution**.
- If your data was actually **normally distributed**, then the points should be close to this **orange** line.
- This **QQ plot corresponds** to a data that’s **not Gaussian**. This is especially obvious if you look at the two marked areas where the scatter plot really splits from the orange line.
- Also, There's more concentration of points on the area to the left than the one to the right is a sign that the data is skewed.

![Untitled](Images/ProbabilityandStatistics/Untitled%20180.png)

- This **histogram** looks pretty **bell shaped**, and the **QQ plot** with this data confirms it. This time the quantiles are pretty much aligned around the orange line, which suggests a **Gaussian distribution** for the data.

![Untitled](Images/ProbabilityandStatistics/Untitled%20181.png)

# Probability Distributions with Multiple Variables

## Joint Distribution(Discrete)

- We’ve learned the **probability distributions** for **one variable**, But what if we want to look at **two variables,** For that we need a **joint distribution.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20182.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20183.png)

- We can calculate these probabilities easier if we organize the data properly.
- We can turn the counts into a **probability mass function** when we divide everything by number of observations. to get the probabilities for each possible combination of data.

![Untitled](Images/ProbabilityandStatistics/Untitled%20184.png)

- All possible combinations of x and y are what's called a **joint distribution**.
- In this case, it's a discrete **joint distribution** because both ages and heights are **discrete variables**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20185.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20186.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20187.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20188.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20189.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20190.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20191.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20192.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20193.png)

## Joint Distribution(Continuous)

- If the variables are **continuous,** It's called a **joint distribution of continuous variable.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20194.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20195.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20196.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20197.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20198.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20199.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20200.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20201.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20202.png)

## Marginal and Conditional Distribution

- Say that I have a distribution of ages and heights, but I don't care about age anymore, I just want the distribution of heights. What I have to do is aggregate over all the ages. That’s called a **marginal distribution**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20203.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20204.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20205.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20206.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20207.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20208.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20209.png)

## Conditional Distribution

- Another thing I can do is take slices. For example, I have the full distribution of age and height. And you want the height distribution of people of age 30, So what you do is take a slice and that is called the **conditional distribution**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20210.png)

- If you fix X=9, then you are only looking at this row. Of the whole table, That is my probability distribution of height for kids of age 9.
- If I want to find for example, P(y) given x=9 of 49, then that's going be this value over here.
- However, there's a small caveat. Notice that in a probability distribution, everything has to add to one. The numbers in this row do not add to one because they add to 4/10.
- What you can do is to **normalize,** **Divide** everything by the **row sum.**
- Notice that **normalizing** and **dividing** by the **row sum** is actually applying the **conditional probability rule**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20211.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20212.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20213.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20214.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20215.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20216.png)

## Covariance of a Dataset

- **Covariance** captures the relation between two variables.

![Untitled](Images/ProbabilityandStatistics/Untitled%20217.png)

- How to calculate **covariance?**
    - First, We will center the graphs by subtracting the **mean** of X from the x coordinates and the **mean** of Y for the y coordinates in order to get this **center** point to be at the **origin**.
    - Then divide by the **standard deviation** of x and of y in order to have this really nice plots where the X **variance** and the Y **variance** are both one.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20218.png)
    
    - The plot in the left, If you move to the right, the coordinates move up.
    - The one in the middle, there seems to be no rule.
    - The one on the right, if you move to the right, the coordinates move down.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20219.png)
    
    - The **left graph**, The majority of the coordinates of x and the coordinates of y have the **same sign**.
    - The **right graph**. The majority of the coordinates of x and the coordinates of y have **opposite** sign.
    - The one in the **middle**, nothing seems to happen. It seems like a land with no rules.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20220.png)
    
    - Notice What happens when take the sum of the product of coordinate X and Y.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20221.png)
    
    - This is the formula for **covariance,** It is the sum of the products x, y but, You first have to **center** the data and then take the **average** of all these products.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20222.png)
    
    - The **Covariance** will tell us if one variable has influence on the other one.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20223.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20224.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20225.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20226.png)
    

## Covariance of a Probability Distribution

![Untitled](Images/ProbabilityandStatistics/Untitled%20227.png)

- If you look at each player at a time, by taking the **expected value** of each players.
- It turns out all three games have the same **expected value**, So these games are basically the same if you only think of one player at a time.
- It turns out that these games are also similar in terms of **variance**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20228.png)

- So in order to get the difference we have to look at both players at the same time, So we need to look at the **covariance.**
- The **Covariance** of the first game is 1, Means it is positive shows this correlation show that if player one wins, player two also wins.

![Untitled](Images/ProbabilityandStatistics/Untitled%20229.png)

- Game 2 is the complete opposite. This one has a covariance of -1, which show that if player one wins, player two loses and vice versa.

![Untitled](Images/ProbabilityandStatistics/Untitled%20230.png)

- Game 3 has a covariance of 0, which means we can’t infer the relation between the two players.

![Untitled](Images/ProbabilityandStatistics/Untitled%20231.png)

- What about a game 4 with 3 players and **unequal probabilities**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20232.png)

- Since we have unequal probabilities, We need to modify the covariance formula.

![Untitled](Images/ProbabilityandStatistics/Untitled%20233.png)

- We get a positive **covariance** because they win and lose together.

![Untitled](Images/ProbabilityandStatistics/Untitled%20234.png)

- The **Covariance** of a **joint continuous distribution.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20235.png)

## Covariance Matrix

![Untitled](Images/ProbabilityandStatistics/Untitled%20236.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20237.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20238.png)

## Correlation Coefficient

- Can we tell the **correlation** is stronger using the **covariance**? No, because it could be that the numbers in the right are just much bigger numbers.

![Untitled](Images/ProbabilityandStatistics/Untitled%20239.png)

- Here comes the **correlation coefficient**, It is a number that lies between -1 and 1.
- **-1** is when you have two variables that are completely **negatively correlated**.
- **1** is when you have two variables that are completely **positively correlated.**
- **0** is when they're completely **independent**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20240.png)

- The **correlation coefficient** is simply the **covariance** except divided by **sigma x sigma y**, so it's a **standardized covariance**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20241.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20242.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20243.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20244.png)

## Multivariate Gaussian Distribution

- The **Gaussian distribution** in more variables is called the **multivariate Gaussian.**
- If you have two variables and look at their marginals and notice they are both **gaussian distributions.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20245.png)

- If the two variables were **independent**, then the **joint PDF** will be the **product** of the **marginal PDFs.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20246.png)

- Both distributions are **bell-shaped**, but in the **independent** case, the distribution is completely **symmetric**. In the **dependent** case, you see that distribution is **elongated** along a line with positive slope.

![Untitled](Images/ProbabilityandStatistics/Untitled%20247.png)

- The **dependent distribution** on the right has some **deformation** because it turns out there is a **positive correlation** between height and weight
- On the left, you would have two **independent** variables, and thus you have those circles.

![Untitled](Images/ProbabilityandStatistics/Untitled%20248.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20249.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20250.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20251.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20252.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20253.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20254.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20255.png)

# Population and Sample

## Population and Sample

- The **sample size** could be anything smaller than the **population size**, The idea is to pick a number that is small enough to be manageable, but also large enough to significant.

![Untitled](Images/ProbabilityandStatistics/Untitled%20256.png)

- When taking a **sample** from a **population**, **Random Sampling** is better in estimating the **population** properties.

![Untitled](Images/ProbabilityandStatistics/Untitled%20257.png)

- If you want to run the experiment again, so you take another four people. Well, This is not good Because you took the first sample set at random. But the second one depends on the first one because you couldn't repeat the people.
- The second sample isn’t good Because it is **dependent** on the first one.

![Untitled](Images/ProbabilityandStatistics/Untitled%20258.png)

- You have to start all over every time. People are allowed to be **repeated** and that is very important.

![Untitled](Images/ProbabilityandStatistics/Untitled%20259.png)

- You have to make sure is that the **samples** are **identically distributed**. Whatever rule you use to pick the first one needs to be the same rule you use to pick the second one.

![Untitled](Images/ProbabilityandStatistics/Untitled%20260.png)

- In machine learning and data science, we often use **samples** to train models and make predictions because we can't look at the entire universe of data.
- It is important to have a **representative** dataset. Having a **representative dataset** means the **distribution** of your dataset is the same as the one for the population.

![Untitled](Images/ProbabilityandStatistics/Untitled%20261.png)

## Sample Mean

- The **population mean** is called $\mu$ .

![Untitled](Images/ProbabilityandStatistics/Untitled%20262.png)

- The **sample mean** is $\bar x$.

![Untitled](Images/ProbabilityandStatistics/Untitled%20263.png)

- We have two sample size of 6 below, $\bar x_1$ has a better estimate of the **population mean**, due to the fact that we did more **random sampling**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20264.png)

- It’s good to know that the **bigger** the **sample size**, the better the estimate you're going to get from your **sample** of the **population mean.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20265.png)

## Sample Proportion

![Untitled](Images/ProbabilityandStatistics/Untitled%20266.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20267.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20268.png)

## Sample Variance

- **Variance** is a measure of how spread out your data is. It is related to how far points are from their **mean**.
- In statistics you usually won't have access to the entire **population**. You'll only have a **sample**. you won't have $\mu$ or N.

![Untitled](Images/ProbabilityandStatistics/Untitled%20269.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20270.png)

- Using **sample mean** in **sample variance** equation introduced some errors that make this equation a little bit **biased.**
- **Bias** is a term in statistics that just means that the formula here will either over or underestimate the value it's targeting.
- In this case, This equation would slightly **underestimate** the true value of the **population variance**.
- This doesn't mean that our first estimation is wrong, but maybe we can improve this undershooting of **variance**.
- To solve the **bias** problem introduced from using the **sample mean** instead of the **population mean**, We will adjust the **variance formula**, By subtracting one from **sample number n.** we will call this new way to estimate **variance** $s^2$

![Untitled](Images/ProbabilityandStatistics/Untitled%20271.png)

- Notice that if using **n or n-1** makes a **significant impact** on your estimated variance, You might have bigger problems than deciding whether to divide by **n or n-1** because it probably means you have a **small sample size** and should be wary of making strong conclusions.
- Also Some accepted statistical techniques use **n** in the **denominator** to estimate **variance**. For example, **maximum likelihood estimation.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20272.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20273.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20274.png)

## Law of Large Numbers

![Untitled](Images/ProbabilityandStatistics/Untitled%20275.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20276.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20277.png)

## Central Limit Theorem - Discrete Random Variable

- If you take any distribution, It can be as skewed as you want. Then take a few samples, always the same number, and look at the average, and do this many times, and plot all these averages. You will get a **normal distribution**. This is called the **central limit theorem**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20278.png)

- It looks a lot like a **Gaussian** or a **Normal distribution**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20279.png)

- This is an example of the **central limit theorem**, that says that as you increase the number of variables you are adding the distribution of this sum. Your distribution looks more and more like the **Gaussian distribution**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20280.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20281.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20282.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20283.png)

## Central Limit Theorem - Continuous Random Variable

- let’s see central limit theorem considering a continuous random variable, The variable follows a **uniform distribution**. Remember that a **uniform distribution** models situations where every interval of the same length has the same chance of occurring, which leads to a constant **probability density function**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20284.png)

- What happens to the distribution when take **averages** of **n** samples as **n** increases?
    - When **n** is 1, It looks like a uniform density because each sample of y1 comes from a uniform 0 to 15 distribution.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20285.png)
    
    - When **n** equal **2,** you get a **histogram** that looks like a **triangle**. Note that it's almost symmetric around 7.5, which is the **population mean** of the wait times.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20286.png)
    
    - When **n** equals **3,** You get a nice histogram that is starting to look more and more **bell-shaped** and is still symmetric around **7.5.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20287.png)
    
    - When **n** equals **5**, it's more **bell-shaped** and it also has lower **dispersion**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20288.png)
    
    - The green lines correspond to the **kernel density estimation,** As you can see, as **n** increases, these curves look more and more like the **Gaussian probability density function**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20289.png)
    
- What is the **mean** and **variance** of the variables $Y_n$?
    - For the **mean:**
        - The ****mean of $Y_n$ is by definition the **expectation** of the **average** of **n** variables $X_i$.
        - By linearity of the **expectation**, this is the same as $\frac {1} {n}$ times the $\sum$ of the **average** of **n** variables $X_i$.
        - But since all variables are **identically distributed**, it is $\frac {1}{n} * n * E[X]$ , which is simply $E[X]$.
    - For the **variance:**
        - Note that the constant $\frac {1} {n}$ comes out of the **variance squared**.
        - Also, because the **variables** are **independent** and since all variables are **identically distributed.** it is $\frac {1}{n^2} *n*Var(X_i)$ which is simply the $\frac {VAR(X_i)} {n}$ .
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20290.png)
    
- Let's plot the **probability density function** for a **Gaussian** with the same **mean** and **variance** $Y_n$. The plots over here confirm that the green and orange lines fit together more closely as **n** increases.

![Untitled](Images/ProbabilityandStatistics/Untitled%20291.png)

- Is the gaussian distribution appear always by average 3 to 5 variables?
    - It is not usually the case that by **averaging three** or **four** samples you will start seeing the **normal distribution**.
    - In general, A safe rule is that you usually need about **30** variables before the **bell-shaped distribution** appears, It depends on the original distribution of the data.
    - If the original population is very skewed, then you usually need more samples than if you are working with a symmetric distribution. In the case of the **uniform distribution**, the **Gaussian PDF** curve appears very quickly as we saw in the previous example.
- How to visualize these distributions?
    - One of the most common ways to visualize these distributions is by **standardizing**.
    - This is because the **mean** is always the same as the **population mean**, but the **variance** depends on **n**.
    - It's easier to compare the distribution of $Y_n$ for different values of **n** when you **standardize** this average.
    - So by standardizing you see that as **n** **increases** the distribution of the **average** is close to a **standard normal distribution**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20292.png)
    
- Whenever you consider the average of **n independent identically distributed random variables**, the **mean** of $Y_n$ is the same as the **population mean**.
- The **variance** of $Y_n$ is the **population variance** divided by the **number** of **variables** you are **averaging**.
- The **mean** stays the same but the **variance** gets **smaller,** This makes sense because the more variables you take the more likely you're going to be closer to the population mean, so there is less spread and less variance. This result holds true no matter what the distribution of the original population is.

![Untitled](Images/ProbabilityandStatistics/Untitled%20293.png)

- Formally, the **central limit theorem** states that as **n** goes to **infinity**, the **standardized average** will follow a **standard normal distribution**. In practice, this is usually true for **n** around **30** or higher, sometimes even with smaller samples.

![Untitled](Images/ProbabilityandStatistics/Untitled%20294.png)

# Point Estimation

## Point Estimation

- **Estimation** is fundamental to statistics and it comes in different flavors.
- We will start with **point estimation,** Introducing the most common **point estimation** method that's called **maximum likelihood estimation** or **MLE**.
- It is very popular in machine learning. **MLE** can be generalized using **Bayes theorem** to a **Bayesian version** of a **point estimator** called the **maximum a posteriori estimation** or **MAP**.
- **Maximum a posteriori estimation** can be thought of a **maximum likelihood estimate** with **regularization**. **Regularization** being a commonly used method in machine learning to prevent **overfitting**.

## Maximum Likelihood Estimation: Motivation

- **MLE** is widely used in machine learning to train models.
- The concept behind **MLE** is very simple. Imagine you have some evidence of something and you want to find the scenario that may have led to that evidence so you pick out of all the possible scenarios, the one that created the evidence with the highest probability.
- We will use the condition probability that gives us the highest probability. This is called **maximum likelihood**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20295.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20296.png)

## MLE: Bernoulli Example

- If we want to generate 8 heads, 2 tails and there's three possible coins. The coin that most likely produce 8 heads and 2 tails, is the one that **maximizes** probability of 8 heads 2 tails given coin and that is the first one because this **conditional probability** is highest for coin one.

![Untitled](Images/ProbabilityandStatistics/Untitled%20297.png)

- Is there a better coin that can do better?
    - Now we want the **P** that **maximizes** the chances of seeing 8 heads and 2 tails. That's the **likelihood**. The **likelihood** is the **probability** of seeing this data based on the model, which is a coin with probability **P**.  Notice that this is a function of **P**, so we have to **maximize** it.
    - Since we don't want to deal with **products** of many things, especially when we're talking about small numbers. We will take the **logarithm**, which is a pretty standard trick we use to turn **products** into **sums,** which makes **differentiation** easier. That gives us the **log-likelihood.**
    - Then we take the derivative with respect to **P** of the **log-likelihood** to find the value of **P** that maximizes the **likelihood.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20298.png)
    
- Here is the general case:
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20299.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20300.png)
    
    - Notice that $\hat p$ is precisely the **mean** of the **population**. If we had k heads among this population of coins, then the optimal probability to obtain those **k heads** would be precisely **k** over **n**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20301.png)
    

## MLE: Gaussian Example

- If we have some observations. These observations were sampled from some distribution, Let's say we have two normal distribution candidates, The question is which one of these two do you think is more likely to have generated the observations?
    - put the observations on the graphs and look at the heights of those points at each graph, It turns out that these heights are probabilities. Well not exactly, they're likelihoods.
    - You can see that the bottom curve, the one with mean two, produces both points with a **higher likelihood**.
    - So we conclude that among these two, it's the bottom **Gaussian**, the one with **mean 2** and **standard deviation 1**, the one that probably generated them.

![Untitled](Images/ProbabilityandStatistics/Untitled%20302.png)

- let’s say we have **3 Gaussians**:

![Untitled](Images/ProbabilityandStatistics/Untitled%20303.png)

- Notice That the mean for the **original data** set is **zero**. It's the same one as the one of the **winning curve**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20304.png)

- Let’s say we have 3 normal distributions with the same **mean** but different **standard deviation.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20305.png)

- Notice that the **variance** of the observations is calculated as the **average** of the **squares** of the **distances** from the **mean**.
- Notice that we are dividing by **2** using the formula for **population variance**, not the **sample variance**. This is because, as mentioned, the **population variance** is **biased**, hence to obtain an **unbiased estimator**, it should be divided by **n-1** instead of **n**. However, the **maximum likelihood estimator (MLE)** for the **variance** is **biased** and equals the **population variance**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20306.png)

- This the [mathematical formulation for MLE for gaussian population](https://www.coursera.org/learn/machine-learning-probability-and-statistics/supplement/tipay/mle-for-gaussian-population).

## MLE: Linear Regression

- let’s say we have some points, we’re trying to fit a line to them, but let's not try to fit a line to them, We will do it with probability.
- let’s say we have 3 candidates and The best fit is going to be the one that's going to give the **highest probability**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20307.png)

- How a line can generate points?
    - The idea is that these **lines** generate points close to the **line**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20308.png)
    
    - Let's say we have a **model** and a **point x**, draw a point on the **line** from **x**. You're going to generate a point close to the line using a **Gaussian**. We put a **Gaussian**, and we **center** it at the point where the line meets the **horizontal line**. We're going to sample out of that **Gaussian.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20309.png)
    
- How to find the line that produces these points?
    - Coincidentally, The line that best produce the points is  going to be the same **best fit** of a line from **linear regression, Why?**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20310.png)
    
- Why ****The line that best produce the points is  going to be the same **best fit** of a line from **linear regression?**
    - Let's say that the **line** has **equation** $y = mx+b$, and the **gray** points are the points of **intersection** with the **line** and the **blue** points are the generated points.
    - The **distances** are going to be called $d_1, d_2, d_3, d_4,$  and $d_5$.
    - First, let's calculate the **likelihood** of generating a point. Since we have a **Gaussian**, This means the **Gaussian** is **centered** at the point where $x_1$ intersects that **blue** line.
    - If we assume that it's a **Gaussian** with **standard deviation one** and **mean** equal **0**, then the **likelihood** of generating these point is given by the formula of the **Gaussian.** That is the **Likelihood** of draining the first point.
    - If we're looking at all of them, Then that's the product of the **five likelihoods**. We have to **maximize** the **likelihood** of the line generating all those points.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20311.png)
    
    - Since they're **independent**, then we have to look at the **product** and do some cleaning:
        - Step 1: Remove the constants,
        - Step 2: Notice that if we **maximize** something, that's the same as **maximizing** the **logarithm** so we can get rid of this **e**, and also to the **1/2** because that would just be multiplying by **2**.
        - Step 3: Since we have a **negative** number here. That means we have to **minimize** the **sum of squares**. **Minimizing the sum of squares** is precisely the **least square error**. This is exactly what **linear regression** is.
    - In **linear regression**, you want to find the blue line that **minimizes** the sum of **squared distances** from the point. This shows that finding the line that most likely produce a point using **maximum likelihood** is exactly the same as **minimizing** the **least square error** using **linear regression**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20312.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20313.png)
    

## Regularization

- Imagine we have a dataset and we have three models that could have generated that data set. One is **linear**, the other one is a **quadratic polynomial** and the other one is a **polynomial of degree ten**.
- In order to find out which one was more likely to generate it, we look at **loss**, which could be the **squared error**.
- The **first model** didn't fit the data really well. The **second model** fitted a little better and the **third one** fitted really well.
- However, The **second one** can better **generalize** than the **third model**. That’s why we are going to apply **regularization** to help us not pick that model three, which is a little chaotic, even though it fits the data pretty well.
- we're going to apply a **penalty** to each one of these models. And the more **complicated** the model, the **higher** the **penalty**.
- we will use $L_2$  **regularization**. It's the sum of the **squares** of all the **coefficients** of the **polynomial**, except for the **constant** one.
- The **new loss** is going to be the **sum** of the **old loss** and the **penalty**.
- What we did here is we modify the **loss** and we **penalize** the models that are too **complex**. In that way, we're sort of trying to find the **simplest model** that fits the data well.

![Untitled](Images/ProbabilityandStatistics/Untitled%20314.png)

- Regularization term:
    - The model has this equation of a polynomial
    - The **log loss** is  $ll$
    - $L_2$  **regularization error** is **sum** of the **squares** of the **coefficients** except the constant
    - A **regularization parameter**, because sometimes we don't want to apply the full penalty, we want to multiply it by a small number in order to not be too drastic here.
    - The **regularized error** is simply the **log loss** plus the **regularization parameter** times the $L_2$ **regularization error**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20315.png)

## Back to Bayesians

- Given an example where was popcorn on the floor and two possible scenarios, And we're trying to investigate which scenario happened.
- **First scenario** is that we were watching **movies**, and the other one that there was a **popcorn throwing** contest. So movies create popcorn in the floor with **high probability**, but a **popcorn throwing** contest would create popcorn in the floor with a **very very** **high** probability.
- It's almost for sure that if you have a popcorn throwing contest, that you ended up with popcorn in the floor. So that's the winner. However, something tells us that movies should be the winner and not popcorn, **why**?
    - One reason is that it's **likely** that you could have been **watching movies**. A **popcorn throwing contest** is **not** very **likely**. It's a very unlikely event.
    - So even though it's more likely to have generated the evidence, it's less likely to have happened on its own, and that should matter. And that should mean that we want to pick movies.
- What we did before is **maximize** the probability. So we figure out that $P(popcorn|movies)$ is less than $P(popcorn|contest).$
- However, the probability that you're **watching** a **movie** by itself is actually **higher** than the **probability** that there was a popcorn contest, So we should factor this into the equation.
- So we should actually multiply them. And when we have the product, then the inequality goes in the other direction. And it turns out that it's more likely to have watched a movie.
- Notice that $P(popcorn|movies)P(movies)$ resembles $P(A|B)P(B)$, which, as we know, is the probability of **A** intersection **B**, the probability of **A** and **B** happening at the same time. So therefore, we're trying to maximize the probability that there's popcorn and a movie and the probability that there's popcorn and a contest.

![Untitled](Images/ProbabilityandStatistics/Untitled%20316.png)

## Bayesian Statistics - Frequentist vs. Bayesian

- The root difference between the approach taken by **Bayesians** and the approach taken by **frequentists** lies in the way they **interpret** **probabilities**.
- The big difference between a **frequentist** and a **Bayesian** is that **Bayesian** introduced the idea of previous belief, also known as **prior**.
- **Prior** represents the statistician's belief before gathering samples, It is the initial belief that you have about the model. However, after getting some samples, they are willing to adjust their belief to account for whatever they just saw, if that aligns with their original beliefs or not.

![Untitled](Images/ProbabilityandStatistics/Untitled%20317.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20318.png)

## Bayesian Statistics - MAP

- Imagine you have three Bayesian play the same game where they just found a coin on the street and want to figure out the probability of the coin landing heads.
- The **first** one is absolutely convinced that the coin should be fair and thus choose a **prior** that is very narrow centered around **0.5**. The **narrow** curve represents a strong belief that the coin is heads 50% of the time with very quick drop-offs to **0** in either direction.
- The **second** **Bayesian** still thinks the coin should be **fair**, but they're willing to believe the coin might have a bias one way or the other. Thus, they choose a **prior** that is also greatest at **0.5**, but more spread out than the first one.
- Lastly, The **final Bayesian** doesn't want to assume anything, so they assign the **same weight** to each possible value. This is called a **non-informative** prior since it doesn't add any information.
- What happens to each of the statisticians beliefs if after one coin toss they see heads?
    - The conservative one almost doesn't shift their beliefs.
    - The one in the middle updates their belief but also varies slightly.
    - The last one however changes their beliefs drastically, going from something that weighted all possible values the same, to one that assigns small probability to small values of **p** and increases linearly as **p** increases.
- What happens if they keep tossing the coin so that in total they got 8 heads and 2 tails?
    - The first one is still super tied to their beliefs. The curve hasn't moved one bit.
    - The second one started shifting their belief. Notice that the curve looks narrower and it no longer peaks at 0.5 but rather around 0.65.
    - Finally the third statistician is the one who changed its belief the most. They went from not having any information to being pretty sure the probability of heads should be around 0.8.
    - Even though all three Bayesians observe the same data, because they started with different **prior** beliefs, their final beliefs are different.

![Untitled](Images/ProbabilityandStatistics/Untitled%20319.png)

- These curves representing beliefs can be very informative to look at. They show not just one likely outcome, but how strongly a **Bayesian** believes every possible outcome is to be the true underlying value.
- However many times you still want to have one **representative** value for the parameter. How can you do that from your **updated beliefs**?
    - There are actually many criteria to choose this value, but one of the most used ones is to choose the value with the **highest probability**.
    - This means taking the value of the parameter that **maximizes** your **belief**. In other words, just take the **mode** of your **updated beliefs**.
    - The **updated belief** is  called your **posterior beliefs**. Just as your **original belief** is called your **priors** because they're your beliefs **prior** to observing the data, the **updated belief** is called a **posterior** because it represents your **belief** after seeing the data
    - Because the **updated belief** is called a **posterior**, this estimation of the **parameter** is called **maximum a** **posteriori** or **MAP.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20320.png)
    
- For the very conservative Bayesian, the **map estimation** for the probability of **heads** is **0.501**. As you can see, it almost didn't budge from the **original assumption** that the coin is **fair**.
- The **second statistician** would say that the probability of seeing **heads** is **0.607**. It has significantly changed, but it's still not too extreme even though they were presented with 8 heads and 2 tails, which from a **frequentist approach** could suggest an even more biased coin.
- Finally, the third statistician would say that the probability of heads is 0.8. It's the same conclusion a frequentist would come to. In fact, any time you use **MAP estimation** with an **uninformative prior** that **weights** all possible values **equally**, the result is identical to what you would get from a **frequentist approach**. This reinforces how important and unique the inclusion of **priors** is within **Bayesian statistics**

![Untitled](Images/ProbabilityandStatistics/Untitled%20321.png)

## Bayesian Statistics - Updating Priors

- How to perform belief updates?
    - It starts with **Bayes' theorem**, So how all four parts of this equation work together By taking your **prior beliefs** on the probability of an event and updating them to create new **beliefs** or **posterior** beliefs based on new **evidence**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20322.png)
    
- Given an example of determining whether you have a fair or a biased coin.

![Untitled](Images/ProbabilityandStatistics/Untitled%20323.png)

- By completing the calculation, you used to think there was a 0.75 chance your coin was fair but after getting your **posterior**, You believe that there's only a **0.65** probability that your coin is **fair**.
- Also you used to think there was a 0.25 chance you coin was biased, New posterior belief that the probability the coin is **biased increases** to **0.348**.
- Notice that the sum of these two beliefs is still **1**, which makes sense. You know that the coin is either fair or biased.

![Untitled](Images/ProbabilityandStatistics/Untitled%20324.png)

- The example is discrete, with only two possible values of **y** and two possible values of **x.**
- This is  the generalized way using **probability mass functions**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20325.png)

- This is what happens if either variable is **continuous**:

![Untitled](Images/ProbabilityandStatistics/Untitled%20326.png)

- In many machine learning contexts, you are solving for the probability that a parameter in a model takes a certain value.
- In these instances, it can be more common to replace the $Y$ in these expressions with capital or lowercase $theta$.

![Untitled](Images/ProbabilityandStatistics/Untitled%20327.png)

## Bayesian Statistics - Full Worked Example

- We will have a complete worked example where you collect more data and iteratively update your priors.
- This time you toss your coin 10 times to collect more data. You see 8 heads followed by 2 tails.
- How can you use this data to update your beliefs about your coin?
    - We need to start framing the situation using **Bayes' theorem.**
    - You can think of your coin's probability of coming up **heads** as a **random variable**, which you'll call **theta**.
    - To capture this data, you can say that if your **random variable** big **theta** took a particular variable little **theta**, then each $X_i$  is a **Bernoulli distribution** for that value, little **theta**.
    - For this version of **Bayes' theorem:**
        - You'll use **probability density** function for **theta**, because it is a **continuous random variable**.
        - ****You’ll use **probability mass function** for **X,** because **X** is a **joint distribution** of **discrete** **random variables.**
    - your first step is to calculate the **likelihood** of seeing these flips given a particular value of **theta**, Since each flip is **independent**, you can just multiply the probabilities across.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20328.png)
    
    - Next, We need to choose our **priors**, expressed as a **PDF** for the variable **big theta**.
    - Suppose we don’t have any **prior beliefs** about the probability the coin comes up heads. Any value between **0** and **1** seems equally likely.
    - In that case we would choose a **uniform distribution.**
    - Write the equation, get your **posterior** which is the **distribution** we are solving for, Add the **conditional probability** of observing the data,.
    - Multiply by the **prior,** In this case is **1,** Since **theta** is always between **0** and **1,** we’ll drop it to make the notation simpler.
    - Finally, **divide** by the **probability** of **observing** the data you saw. This last value can be tricky to solve for, but recall it is going to be some constant value that ensures the total **area under** the **PDF** is equal to **1**.
    - We can ignore this constant. In this instance the distribution we have is called the **beta distribution**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20329.png)
    
    - You went from a **uniform prior belief** to this **posterior** which is definitely a lot more informative.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20330.png)
    
    - We are going to remove the **constant** term so this new expression just says the **posterior pdf** on the left is **proportional** to the **product** on the right.
    - We can do that, Because you can think of this **first expression** as the probability of the data given that model of the coin little **theta**. The **second expression** meanwhile measures how likely that model is.
    - In this case, you assign the same **likelihood** to each value of **theta** with a density of **1**.The result was itself a **PDF.**
    - If you want to summarize this set of beliefs with a single number, That's going to be the **MAP estimate**, The **maximum a posteriori** value of theta.
    - Remember that the **MAP estimate** is simply the **mode** of the **posterior** distribution, or in other words, the value of **theta** that made the **posterior** maximum.
    - This is why you can ignore the **constant**. All that **constant** in the denominator did was **scale** the curve of your new PDF.
    - Including these **constants** won't change the shape of your **curve** and most importantly, it won't change which value of theta gives the **maximum**.
    - Using argmax to get theta that **maximizes Map estimate**. In this case,  theta hat, that **maximizes** your **posterior pdf** is equal to 0.8.
    - This is the exact answer of a **frequentist,** Because you have a **non-informative prior**, Then the **MAP** is the same **MLE** estimation.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20331.png)
    
    - **Uninformative priors** are just **constants**, and just like the constant in the denominator, they don't affect the shape of the curve or the location of the **maximum**, so you can ignore them.
    - The only term you're left with is the **probability** of the **data given** the model, and **maximizing** that probability is all **MLE** does.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20332.png)
    
- What happens if your **prior** is **informative**?
    - Let's flip your coin 10 more times. This time you get a sequence with 6 heads and 4 tails.
    - Remember that after the first 10 coin flips you went from a **uniform prior** to the **pdf distribution**.
    - If we want to keep updating our beliefs, then we can consider the **pdf** as our new **prior**, It is our most recent **belief**. This is the standard way of updating models in **Bayesian statistics**.
    - When you want to incorporate new data, you just make your **posteriors** your new **priors** and repeat the process from before.
    - Next, We need the probability of getting this sequence of coin flips given a particular value of theta. which you multiply, because all variables are **independent.**
    - Repeat the process from last time to update your **beliefs**. You first have the **probability** of **observing** your coin **flips multiplied** by the new **prior**, and again everything is divided by a **constant**.
    - Just like the last time, this is another **beta distribution**, We are going to ignore solving for the **constant** since it won't change our results.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20333.png)
    
    - Let's see what the curves look like.:
    - The **map estimate** of **theta** for your new curve is still the **highest** point in the **posterior** distribution, which is now **0.7**.
    - A first interesting fact is that this time your **priors** were **informative**, and they clearly mattered. If a **frequentist** only saw that **second set** of **10** flips, they would conclude that **theta** is **0.6.** Y
    - A second interesting fact is that out of **20** total flips, **14** were heads, so after seeing all **20** flips, a **frequentist** would have also concluded that **theta** is **0.7**.
    - In fact, a **Bayesian** starting from an **informative priors** would also conclude the same.
    - This shows is that it didn't matter that you incorporate your data in two chunks. This **property** holds in general for **Bayesian** statistics. Whether you incorporate all the data at once or in chunks, your final **posterior beliefs** will be the same.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20334.png)
    
- The main idea behind **Bayesian statistics** is to update your prior beliefs using data. As you collect more data, your old posterior beliefs become your new priors and you update them using the new data.
- If your priors are **uninformative**, **MAP** is actually just a complicated way to do the same thing as **MLE**.
- Assuming you don't have wildly poorly behaved priors, **MLE** and **MAP** estimates will converge as you collect more data.
- Statisticians tend to choose **Bayesian approaches,** Because they are best for instances where you either have limited access to data or strong prior beliefs.
- If you are going to collect a lot of data anyway, **frequentist** approaches are probably fine.
- A potential **downside** of **Bayesian statistics** is that if your **priors** are wrong, you can make **wrong conclusions**, especially with **limited data**, your **priors** will have a strong **influence** on the conclusions you draw.

![Untitled](Images/ProbabilityandStatistics/Untitled%20335.png)

## Relationship Between MAP, MLE and Regularization

- how **regularization** and **maximum likelihood** actually match?
    - Let's say you have this data and you have three models that could have fit that data and each one of them generates the data with some probability.
    - Remember that a model can generate the data as we saw before by simply creating a Gaussian at every point on the line and generating points close to the line or to the curve.
    - We are going to pick the line that generated the data with the highest probability, in this case the third one.
    - However, If we take into account the probability that the model has been picked. Now, the simpler the model, the more likely to have been selected.
    - So what we're going to do is we're going to multiply these probabilities and now the winner is not the third one now perhaps the winner is the second one.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20336.png)
    
    - In **regression** you have some **loss** that could be the **square loss** and in **maximum likelihood** you're going to **maximize** the probability that the data was created with the model.
    - If we add Bayes to the maximum likelihood, Then we have to multiply here by the probability of the model.
    - If we do regularization and regression, Then we add the **regularization** term.
    - In order to turn the left into the right, a good way is to turn **products** into **sums** by taking **logarithms.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20337.png)
    
    - However, We don’t know what is probability of a model here. we can get the probability or likelihood of a model by getting the equations for the models, Then pick these **coefficients** out of a **standard normal distribution**. Therefore the **likelihood** of each model is the product of theses **coefficients**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20338.png)
    
    - let's try to fit the best model, We want to **maximize $P(Data|Model)$** times $P(Model)$ is the same as **minimizingthe sum of squares** of the distances which is the **square loss** plus the **regularization term.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20339.png)
    
    - Therefore when we try to pick the model out of number of models, Then **maximizing** the **probability** of the **model** is the same as **minimizing** the **sum of squares** of the **coefficients,** And **maximizing** the **conditional probability** of the data given the model is the same as **minimizing** the **square loss**.
    - So the **new loss** is going to be the **sum** of the two. And that is how you train a model using **regularization** based on a **Bayesian approach**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20340.png)

# Confidence Intervals

## Confidence Intervals - Overview

- Given a population of average height $\mu$, You took samples from this population to estimate $\mu$. You know that in order to get good samples, you need to apply random sampling, taking larger sample sizes, and making sure that the samples are independent and identically distributed.
- But even with these practices, you know you can't expect any particular sample to be perfectly accurate, Because you get a different sample mean every time.

![Untitled](Images/ProbabilityandStatistics/Untitled%20341.png)

- Since we'll always have some degree of uncertainty about how accurate the sample mean is. Can we use these sample means with some degree of certainty?
    - Statisticians use **confidence interval**, A **confidence interval** is an **interval** of values that is a **lower** and **upper limit** which contain the population parameter.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20342.png)
    
- What is the intuition behind **Confidence interval**?
    - Imagine you're walking along a road, You realize you've dropped your keys somewhere along the road.
    - First, you'll begin to search at your best guess of where you dropped the key. Then you'll walk the some search distance in both direction along the road to look for the key.
    - You need to decide this distance before your search.
    - You could always choose a different place to be your best guess, but that will shift the entire range of the road you'll search.
    - Where you define your best guess is always going to be a guess. The thing that will have the biggest impact on whether you find the key will be your search distance.
    - So how large should your search distance be?
        - To decide your search distance, you think about how confident you need to be that you will actually find the key, which you'll express as a percentage.
        - There's a tradeoff between the level of confidence and the search distance. The Higher level of confidence, The larger search distance you need to walk.
    - The **orange level** is your **confidence interval.**
    - The key never moves, its location is **unknown** but **fixed**. The **interval**, is **randomly generated** with a desired **certainty**, or **uncertainty** that it contains the key. I say randomly generated because one of the ingredients of the interval is that best guess you made of where to start looking.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20343.png)
    
- How to get the confidence interval within a normal distribution with unknown **mean** and known **variance**?
    - Let's assume that heights in population follow a **normal distribution** with a **mean** $\mu$, which is unknown, and a population **variance**, $\sigma ^2$, which is known.
    - The true value of $\mu$ is the key. $\mu$ has a fixed but unknown value. You will randomly generate a **confidence interval** to estimate where it is located. To do that, We will take a random sample from the population.
    - We will create a **random variable $\bar X$** to describe the probability of selecting different **sample means**.
    - It's going to be identical to **X**, a **normal distribution** of $\mu$ and  $\sigma ^2$. This doesn't mean you know the true value of $\mu$, but you do know **X** and $\bar X$have the same **mean**.
    - We are going to ask how far are most **sample means** from the true population **mean** $\mu$, Because if your sample is typical, it will also be within that range.
    - To do this, We need two related concepts, A **margin of error**, which is a distance on either side of $\mu$, and a **confidence level**, which is the probability that your **sample mean** is within that **margin** of error.
    - To set these two values, We need to set the **significance level** which is **alpha $\alpha$**. That is the probability that your sample mean falls outside your margin of error.
    - From alpha you'll calculate your **confidence level**, which is $1 - \alpha$. This is the probability that a randomly generated **sample mean** is within the **margin** of **error**.
    - If you set a **confidence level** of **95%** and since the **normal distribution** is symmetric around its mean, you can say that **2.5%** of the time your sample mean will lie outside the margin of error because it's too big and 2.5% of the time because it's too small. That is just **alpha** divided by two.
    - Finally, The formula for your **confidence interval is** your **sample mean** plus or minus the **margin of error**.
    - This says that if your **sample mean** is one of the **95%** of all **sample means** that is relatively close to $\mu$, then $\mu$ is also relatively close to the **sample mean.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20344.png)
    
- You will find that when your **confidence level** is **95%**, **95%** of your **confidence intervals** will contain the population **mean**, and **5%** of the time they will not.

![Untitled](Images/ProbabilityandStatistics/Untitled%20345.png)

- This is what's meant by a **95% confidence interval**. It means that the recipe you're using to cook up your interval will result in one that contains the population **mean 95%** of the time.
- Remember, You're not going to generate hundreds of **confidence intervals** and you're not going to actually know $\mu$. Instead, you will generate a **single confidence interval**. Does it contain $\mu$? Well, you can never be perfectly sure, but **95%** of **confidence intervals** generated like this do contain $\mu$.

![Untitled](Images/ProbabilityandStatistics/Untitled%20346.png)

## Confidence Intervals - Changing the Interval

- If you increase your **sample size** so **n,** the **mean** of the **sample means** doesn't depend on **sample size**. It will still be the **population mean**.
- The **standard deviation**, however, does depend on the **sample size.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20347.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20348.png)

- How this change in **sample size** affects your **margins** of **error**?
    - As you increase your **sample size**, Your **margin** of **error** shrink.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20349.png)
    
    - Notice when you increase the sample size how the **margins of error** are smaller given a shorter overall **confidence interval**.
    - While the **margin of** **error** is smaller, you also expect the **sample means** here to be closer on average to the true **population mean**. The reason for this is that with larger samples you get **greater accuracy**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20350.png)
    
    - While all the **confidence intervals** have the same **95%** chance of containing the **population mean**, the ones in the **right** are definitely more desirable, because they're smaller. In other words, you have a more precise estimate for the true value of $\mu$ while maintaining the same level of confidence that you're correct.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20351.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20352.png)
    
- What is the difference between **95%** and **70% Confidence interval**?
    - The difference here isn't that the **sample means** on the right tend to be farther away from the population **mean**, but simply that you've chosen to use **small margins** of **error**. And so there are more instances where the overall **confidence interval** does not contain $\mu$.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20353.png)
    

![Untitled](Images/ProbabilityandStatistics/Untitled%20354.png)

## Confidence Intervals - Margin of Error

- the two main ingredients of a **confidence interval** are the **sample mean** and the **margin of error**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20355.png)

- We already know how to calculate sample mean, How to calculate **margin of error**?
    - We are going to assume all we have is **sample mean** and **sigma.**
    - We already know that for any **normal distribution**, roughly **68%** of the curve lies within **one standard deviation** of the **mean**, and roughly **95%** lies within **two standard deviations** of the **mean**.
    - If you know the **standard deviation** of a **normal distribution**, you can establish the range around $\mu$ in which any percentage of the distribution lies.
    - These points that are a specified number of **standard deviation** away from the **mean** is called **z-scores.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20356.png)
    
    - The name **z-score** is taken from the **standard normal** **distribution**, which is often called the **z-distribution,** You can easily convert **normal distributions** to the **standard normal** by subtracting the **mean** and **dividing** by the **standard deviation**.
    - The **z-distribution** has a **mean** of **0** and a **variance** of **1**.
    - If you want exactly **95%** of the distribution, then the **z-scores** to two decimal places are **minus 1.96** and **positive 1.96**.
    - **Negative 1.96** and **positive 1.96** are called **critical values**. They are cut-off points inside of which an exact percentage of a probability distribution is contained.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20357.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20358.png)
    
    - Returning to a **non-standardized normal distribution**, you can still use these **critical values**, but since the **distribution** isn't normalized, you need to **multiply** them by the **standard deviation**.
    - Since, $\bar x$ has a **normal distribution** centered around $\mu$ and with **variance** $\frac {\sigma ^2 } {n}$. The population **standard deviation** is $\frac \sigma {\sqrt {n}}$. This is called the **standard error**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20359.png)
    
- After getting the **sample mean** and **margin of error**, How to get the **confidence interval**?
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20360.png)
    
    - By **subtracting $\bar x$** and $\mu$ from all terms and **multiply** everything by **-1**, you get the **confidence interval**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20361.png)
    
- So far we've assumed we were working with a population that followed a **normal distribution,** However, data isn't always **normally distributed**. Maybe you don't even know how the population behaves.
- All we learned still work because we didn't actually care about the **population distribution**. All we needed was the **distribution** of the **sample mean**.
- This is where the **central limit theorem** slips in to save the day. If **n** is large enough, then by the **central limit theorem**, your **sample mean** will still have an approximately **normal distribution**, and it even has the same parameters $\mu$ and $\frac \sigma n$.
- The process you just learned to develop your **margins of error** will still hold so long as you pick a **large enough sample**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20362.png)

## Confidence Intervals - Calculation Steps

![Untitled](Images/ProbabilityandStatistics/Untitled%20363.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20364.png)

## Confidence Intervals - Example

![Untitled](Images/ProbabilityandStatistics/Untitled%20365.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20366.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20367.png)

## Calculating Sample Size

![Untitled](Images/ProbabilityandStatistics/Untitled%20368.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20369.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20370.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20371.png)

## Difference Between Confidence and Probability

- There's a subtle difference between these two statements.

![Untitled](Images/ProbabilityandStatistics/Untitled%20372.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20373.png)

- The **sample mean**, on the other hand, has a **probability distribution**.
- Saying that you're **95%** confident has to do with repeating the sampling experiment many times and calculating the intervals for each sample estimate.

![Untitled](Images/ProbabilityandStatistics/Untitled%20374.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20375.png)

## Unknown Standard Deviation

- How to find the confidence interval if the **standard deviation of the population $\sigma$** is unknown?
    - If we don’t know the **standard deviation** of the total **population,** All we have to do is make a small change in our calculations by introducing something called the **student t-distribution**.
    - In order to find the confidence interval given some point estimate $\bar x$ but the **population standard deviation is unknown**, we will have to use the **sample standard deviation $s$**.
    - This quantity is no longer a **normal distribution,** It's called the **student's t distribution**.
    - The **student t-distribution** is very similar to the **normal distribution**, but it has much **fatter tails**, meaning that more of the points can be found on these sides compared to the **normal distribution**.
    - If you were to sample a point out of the **student t-distribution**, it's more likely to be far from the center than if you pick it from the **normal distribution**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20376.png)
    
    - With a known $\sigma$, we have a sampling distribution quantity with a **normal distribution,** By using the **z-score** in scaling to find the **confidence interval**.
    - With an **unknown** $\sigma$, we can replace $\sigma$ with $s$, the **sample standard deviation,** and that's a **student t-distribution**.
    - Since **z-score** depends on the **normal distribution,** For the **student t-distribution** this **z-score** changes to a **t-score,** We use a **t-score** to calculate the **margin of error** to fix this scaling issue.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20377.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20378.png)
    
    - **t-distributions** are defined **degree of freedoms**. The **degree of freedom** of a **t-distribution** is given by the number of **samples** that we used **minus one**.
    - What is the effect of the **degree of freedom** in the **t-distribution**?
        - The larger the number of **degrees of freedom**, the closer you get to a **normal distribution**.
        - The more **samples** you use, the bigger **n** is, the closer that your **sample standard deviation $s$**, is to the **population standard deviation** $\sigma$. And if you know $\sigma$, you use a **normal distribution**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20379.png)
    

## Confidence Intervals for Proportion

- How to find **confidence intervals** for **proportions**?
    - Imagine you want to find out the **proportion** of adults who would own a car in a population. You have a sample of 30 people. So **n** is equal to **30**.
    - Calculate the **sample proportion** which is equal **80%.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20380.png)
    
    - Then to calculate a **95% confidence interval** for this **sample proportion, T**he **confidence interval** for the **mean** is similar to the **confidence interval** for the **proportions,** Except that the **standard error** in **the margin of error** is different.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20381.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20382.png)
    

![Untitled](Images/ProbabilityandStatistics/Untitled%20383.png)

# Hypothesis Testing

## Defining Hypothesis

- **Hypothesis testing** is a way to tell if some belief you have of the **population** is likely to be true or false, A very important application of **hypothesis testing** called **A/B testing.**
- How **Hypothesis Testing** works?
    - Let's say you have an **email spam detector** and it determines if a given email is Ham or Spam. By default, we're going to assume that all the emails are ham. And the reason for this is that it's much worse to delete a good email than to accidentally put a spam email on our inbox.
    - So our base assumption is going to be that an email is ham. That's going to be called the **null hypothesis $H_0$**. It's the base assumption when we assume safely that nothing is happening.
    - We also have an **alternative hypothesis** $H_1$, That's the one we are trying to identify.
    - One important characteristic of the **null** and **alternative hypothesis** is that they are **mutually exclusive**. Because the email can't be ham and spam at the same time.
    - The key is to design a good set of **hypothesis.** Notice that if there's a lot of evidence that shows that the email is spam. Then the **null hypothesis** is **rejected** and the **alternative hypothesis** that the email is spam is **accepted** as true.
    - But this doesn't work the other way around. If the **evidence** gathered is not enough to show that the email is spam, then you can **reject** the **null hypothesis**. However, that does not mean that the email is ham, only that we don't have enough evidence to show that the email is spam.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20384.png)
    
    - So in general, you will need to propose your hypothesis. The **null hypothesis** is the **baseline** and the alternative hypothesis represents the **competing** statement.
    - Given the **asymmetry** and the **conclusions**, the **alternative hypothesis** is usually the one you're interested in proving.
    - The goal of **hypothesis testing** is deciding between two **hypotheses** based on **data** and **evidence**.
    - In the case of the spam example. Then this evidence comes in the form of the sender, the attachments, the size of the email, certain keywords, etc. Anything you can use to show that the email is spam.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20385.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20386.png)
    

## Type I and Type II Errors

- Due to the **randomness** of the world and the fact that we only have partial information from the **population** under study, Making perfect decisions is impossible
- What are Types of errors you can get from a test?
    - If you send a ham email to the spam box. This is called a **type I error** or a **false positive**, This happens when you **reject** $H_0$ when it was actually **true**.
    - The other error appears when you incorrectly determine a spam email to be ham email, This is called a **type II error** or a **false negative** and occurs when you don't **reject** $H_0$ and the **hypothesis** was actually **false**.
    - It is important to understand that you can never know if you are right or wrong about your decision because you don't know the **ground truth**. However, you will try your best to determine a **test** where you keep these **errors** below an accepted **threshold**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20387.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20388.png)
    
- Notice that **type I** and **type II** errors don't have the same impact on the problem.
- In the case of the email spam detector, You would rather have an accidental spam email in your inbox than lose a perfectly good email and never be able to read it because the classifier thought it was going to be spam. This means that **type I** **errors** are more severe than **type II errors**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20389.png)

- What is the greatest probability of type I error you're willing to tolerate? Or in other words, on average, how many times are you willing to incorrectly send a ham email to the spam box in order to have a good spam detector that still sends most of the emails to the correct place?
    - The **maximum** probability of **type I error** is called the **significance level** and is usually denoted by the **Greek letter alpha**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20390.png)
    
    - Since it's a probability, it can only take values between 0 and 1.
    - If **alpha** is **0**, it means that whatever **evidence** you get, the email is always considered to be **ham**. In that case, you **never** get a **type I error**.
    - If **alpha** is **1**, that means every email is considered **spam**. And in this case, every time you get a ham email, you will be making a **type I error**.
    - Both extremes are terrible decision makers. What you want is something that is able to define if an email is spam or not and has as few **type I errors** as possible.
    - So a typical value to consider is **0.05** for your **significance level**. This means that on average, you will decide that a ham email is spam **5%** of the time. Another value usually encountered is **alpha** equals **0.01**. As we said, you want alpha to be as small as possible.
    - However, If you reduce the **probability** of a **type I error** too much, then you're increasing the **type II error**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20391.png)
    
    - The proper definition of **significance level**, it is the **maximum probability** of committing a **type I error,** which is the same as the **maximum probability** of **rejecting** $H_o$when $H_0$ was actually **true**. The value of **alpha** is your design criterion for this test. This means that **alpha** will determine a **threshold** to decide if you should **reject** $H_0$ or not based on your sample.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20392.png)
    

## Right-Tailed, Left-Tailed, and Two-Tailed Tests

- Before diving into the **hypothesis testing**, You should consider the **data quality**. Since your goal is to make a decision based on data, then the data needs to be reliable. Otherwise you'll be arriving to false conclusion. This means that each sample has to be **representative** of the **population**, the data needs to be completely **randomized** to avoid introducing **bias** into the decision making, The **sample size**  should be big enough to make a good decision, A good rule of thumb is considering 30 samples or more.

![Untitled](Images/ProbabilityandStatistics/Untitled%20393.png)

- Let’s say you have a historical data that says that the mean height of 18 y/o in the US in was 66.7 inches. Based on the observed data of **sample mean 68.442**, we want to confirm if the mean height of 18 y/o in the US has **increased** or not?
    - First, We need to formulate the **null** and **alternative hypothesis**. Your **baseline** here is that nothing has changed and the **competing hypothesis** is that the population mean is greater than 66.7 inches.
    - Note that the **hypothesis** are always formulated in terms of the **population**, in this case the **population mean**, and must not involve **samples** at all.
    - The **hypothesis** are based on the **population** parameters, but the **decision** will be based on the **observations** that you have. If your **decision** is made on the **sample mean**, then the **sample mean** will be your **test statistic**.
    - Note that **test statistic** is a **random variable** and doesn't yet depend on the particular observations you have.
    - The value **68.442** is called the **observed statistic**, and it is based on your measurements.
    - In general, a **test statistic** will be a function of the **random samples** that gives information about the **population parameter** you want to study.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20394.png)
    
    - If you are **testing** the **mean** of the **population**, a good **statistic** is the **sample mean**. Same thing goes for **testing probabilities** or **occurrence rates**. If you wanted to **test** the **variance** of the **population**, then a good candidate is the $s^2$ **statistic**.
    - It's important to mention that the **test statistics** are **not unique**. For example, the **sum** of **square difference** between the $x_i$ and the **sample mean** could also be used as a **test statistic** for **variance**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20395.png)
    
    - In general, there are three **types** of **hypothesis:**
        - The first one is called a **right-tailed test**, In this case the **alternative hypothesis** extends to the right of the **null hypothesis.**
            - Example: whether the population mean increased during the last 50 years?
        - The second one is called a **left-tailed test**, In this case the **alternative hypothesis** extends to the left of the **null hypothesis.**
            - Example: whether the population mean decreased during the last 50 years?
        - The third one is called a **two-tailed test,** In this case the **alternative hypothesis** extends to the left or the right of the **null hypothesis.**
            - Example: whether the population mean has changed at all, either became bigger or became smaller?
    - Notice that for these cases the **null hypothesis** or the **baseline** is always the same, but the **alternative hypothesis** changing depending on what you want to prove.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20396.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20397.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20398.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20399.png)
    

## P-Value

- Given the Example below, Now that we have a distribution for the statistic, How likely is our sample if $H_0$ is true?
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20400.png)
    
    - Consider the **right-tail test** for the **mean** of a **population** with the **Gaussian distribution,** With a **sample mean** of **68.442**, which is bigger than **67**, We need to determine if the difference is big enough to be **statistically significant** or not.
    - The goal is to make a **decision** with a **type I error** probability of no more than the **significance level** $\alpha$, which in this case we're going to pick **0.05**.
    - In this case, a **type I error** happens when you determine that the **population mean** has increased when the true value of **mean** didn’t change.
    - If you consider that an observed **sample mean** of **68.442** is enough to **reject** $H_0$, Then you would also **reject** $H_0$  if you saw a **sample mean** greater than **68.442**.
    - So if you **reject** $H_0$  every time you observe a **sample mean** greater than **68.442**, then the **probability** of a **type I error** is simply the probability that the **sample mean** is greater than **68.442** given that $\mu$  is **66.7**.
    - The probability we're looking for is the **shaded area**, which has a value of **0.332**. Notice that this value is **less than 0.05**.
    - Since the **maximum probability** of incurring a **type I error** is below the **0.05 threshold** . It makes sense to **reject** the **null hypothesis**.
    - This probability is called the **P-value.**
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20401.png)
    
    - In this example a **right-tail test**, a value as extreme or more extreme than the observed **sample mean** meant that you had to consider all the values **greater** than **68.442**.
    - The **p-value** measures how well your sample is moderate under the **null hypothesis**. A **small p-value** says that your **sample** landed on the **tail** of the **distribution** under $H_0$, so it’s unlikely to happen if $H_0$  was **true**.
    - The **p-value** is a good metric to create a **decision rule** for the **test**. This **decision** will ultimately depend on the **significance value** you choose.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20402.png)
    
- What is the **p-values** look for each type of test?
    - For a marginal case called t-statistic as you defined, t observed as the observed value of the statistics and Mu equals Mu_0, the null hypothesis, where Mu is the parameter you're looking to test.
    - For **right-tail test**, The **p-value** is the **probability** of the **test statistic** is **greater** than the observed value under the assumption that $H_0$ is true.
    - For **two-tailed tests**, you want the **probability** of the **test statistic** is **greater** than or **smaller** than the observed value in both directions under the assumption that $H_0$ is true.
    - For **left-tail test**, the **p-value** is the **probability** of the **test statistic** is **smaller** than the observed value, always assuming that $H_0$  is true
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20403.png)
    
- What is the **p-value** of the **two-tailed test**?
    - In this case, the **p-value** is a **probability** that the **difference** in **absolute value** between the **sample mean** and **66.7** is greater than **1.742** given that $H_0$  is true.
    - For this case, we have to consider **both tails** since you're considering the **absolute value**. This gives a probability of **0.0663**, In this case, the **p-value** is **greater** than **0.05**, so you conclude to not **reject** $H_0$.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20404.png)
    
- What is the **p-value** of **left-tail test**?
    - Notice that this **p-value** is not only **smaller** than **0.05**, but it is also **smaller** than **0.01**, which is another commonly used **significance level**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20405.png)
    
- So far, all the tests we performed using the statistic $\bar X$, which if $H_0$  is **true**, has a **Gaussian distribution**.
- However, there is an alternative way to design the test using the **z-statistic**, which is simply the **standardized** version of $\bar X$. In this case, if $H_0$  is **true**, then the **z-statistic** follows a **standard normal distribution**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20406.png)

- How we can formulate the previous **right-tail test** problem in terms of the **z-statistic**?
    - Notice that the **hypothesis,** the **type I** **error** interpretation need to remain the same. Also, sample data doesn't change.
    - Let's get **z-statistic** which is 1.837.
    - Transform the event $\bar X$ bigger than **68.442** so that the **probability** of **type I errors** is stated in terms of the **z-statistic** and its observed value.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20407.png)
    
    - Since we are working with the **z-statistic**, We need to adjust the **PDF** as of the standard normal distribution. Therefore, the **66.7** turns into a **zero** and the observed **sample mean** of **68.442** turns into the **observed z-statistic** value **1.837**.
    - The result of the **p-value** has to be the same because you're performing the same test over the same data and you're just **standardizing** the statistic.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20408.png)
    

## Critical Values

- A critical value is the most extreme sample you could get so that you would still **reject** $H_0$. This is a sample that has the **p-value** of exactly **Alpha**.
- It depends on the value that you choose for **Alpha**. Different **Alpha** means different **critical values**. The **critical** value ****is usually referred to as $K_{\alpha}$.

![Untitled](Images/ProbabilityandStatistics/Untitled%20409.png)

- For a right-tail test, you're interested in an **Alpha** of **0.05**. You need to find the value of $K_\alpha$ **0.05** which means that the **critical value** is nothing more than the **quantile 1-0.05**.
- One cool thing about **critical values** is that you can define your **decision rule** before having to collect any data. Once you do have your data, you can calculate the **observed statistic** and make a decision from that.
- In our example, the **observed sample mean** is **68.442** which is **greater** than the **critical value 68.26**. In this example, you will reject the **null hypothesis** when a **significance level** of **0.05**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20410.png)

- Here’s what happen when you change your **Alpha** for **0.01.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20411.png)

- How **critical values** look like for each type of **test?**

![Untitled](Images/ProbabilityandStatistics/Untitled%20412.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20413.png)

## Power of a Test

- **Type I error** happens when we **rejected** the **null hypothesis** that the **population mean** was still **66.7** when it was actually **true**.
- **Type II error**, which happens when you **fail** to **reject** the **null hypothesis** when it wasn't **true**.
- Note that **type I errors** can only happen for one value of the **population mean**, in this case **66.7**. However, **type II errors** can happen for any **population mean** value which is bigger than **66.7**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20414.png)

- Given the previous example, you found that for a **significance level** of **0.05**, the **critical** value was **68.26**, and the **decision rule** was to **reject** the **null hypothesis** if the observed **sample mean** is **greater** than **68.26**.
- What is the **probability** of incurring in an error if the true value of the **population mean** was **70**?
    - That's the probability of a type II error. we’re looking for a probability of **not rejecting** $H_0$ given that true **population mean** is **70**.
    - With the proposed **decision rule**, it is the probability that the **sample mean** is **smaller** than 68.26, when the **population mean** is **70**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20415.png)
    
    - So remember that if $H_0$ is true, then the **sample mean** had a **gaussian distribution** with mean **66.7.** However, if the true value of the **sample mean** is **70**, In this case, the **sample mean** will follow a **gaussian distribution** with **mean 70.**
    - The probability of **not rejecting** $H_0$ is the blue area. For values **smaller** than the **critical value** of **68.26,** The **probability of type II errors $\beta$** is **0.033.**
    - The probability here does not depend on the **observed sample**, only on the **significance level** that you chose for the test. Note here, that you considered $\mu$ equals **70**, but you can get the **type II error probability** for any value on $\mu$ in the **alternative hypothesis**. So you can define **beta** for as many values as you want.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20416.png)
    
- Many times you want to characterize the chances of actually making a **good decision**. It is important to focus on this quadrant of the table, where you are making the **right** call by **rejecting** the **null hypothesis**.
- This information is gathered in the **power of the** **test**, which is a function that tells you for each possible value of the population, meaning the **alternative hypothesis**, the **probability** of **rejecting** $H_0$.

![Untitled](Images/ProbabilityandStatistics/Untitled%20417.png)

- Remember that the **type II error** **probability** is the **probability** of **not rejecting** $H_0$, when $H_0$ is not **true**. This was called **beta**.
- The **power of the test** which is the **probability** of making the **right decision**, and **rejecting** the **null hypothesis** when it's **not true**.
- These probabilities complement each other, so the **power of the test** can be written as **1-beta**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20418.png)

- This is what a typical **power of the tes**t looks like for a **right sided test**. At the very left of the plot you have $\mu$ equals **66.7**, and the height of the graph is exactly **alpha**, since it's the **probability** of **rejecting** $H_0$for that particular value of $\mu$.
- All other values of $\mu$ in the graph correspond to the **alternative** hypothesis that the **population mean** is **greater** than **66.7**.
- Consider $\mu$ equal **68**, then the **height** is the **power** of the **test** at $\mu$ equal **68**, and is exactly the **probability** of **rejecting** the **null hypothesis** if the true value of the population **mean** was **68**. The difference between 1 and the graph is the **complement**, and that corresponds the probability of a **type II error** if $\mu$ is actually **68**.
- This graph has an interesting pattern, as the **horizontal axis** values **increase**, the **curve** also **increases**, getting closer and closer to **1.** This makes sense because that the value of $\mu$ determines the **mean** of the distribution of the **sample** **mean**. So as $\mu$ **increases**, the **probability** that the **sample mean** is smaller than the **critical value decreases**.

![Untitled](Images/ProbabilityandStatistics/Untitled%20419.png)

- Let's see how the power of the test looks for three different alpha values. On the left you have the power of the test for alpha with 0.01. Next for 0.05, which is the 1 from the previous slide. And finally, you have the power of the test for a significance level of 0.1.
- From left to right you have an **increasing** alpha, which is the **type I error**. Now consider the value of the function for $\mu$ equals **70**. It turns out that as the value of **alpha increases**, so does the **power of the test** for $\mu$ equals **70**. This is true for every value in the curve.

![Untitled](Images/ProbabilityandStatistics/Untitled%20420.png)

- In contrast, For the **type II error**. The behavior is exactly the opposite. If you get too **restrictive** with the **type I error**, you end up increasing your **type II error** probability.
- For x fixed sample size, there is always a **trade-off** between **type I** and **type II errors.** However, if you can have any sample size you need, you can always achieve **alpha** and **beta** as small as you want.

![Untitled](Images/ProbabilityandStatistics/Untitled%20421.png)

## Interpreting Results

![Untitled](Images/ProbabilityandStatistics/Untitled%20422.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20423.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20424.png)

## T-Distribution

![Untitled](Images/ProbabilityandStatistics/Untitled%20425.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20426.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20427.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20428.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20429.png)

## T-Tests

- The computations will have to be made in terms of the **t-statistics** rather than the **sample mean** directly. So instead of plotting the distributions around 66.7, you will need to draw them around zero.

![Untitled](Images/ProbabilityandStatistics/Untitled%20430.png)

- Notice that this is the exact opposite result you got from the **right tail test** when **sigma** was known. This has to do with the uncertainty added from not knowing the **population variance**. Suddenly, the evidence you had was not enough to **reject** $H_0$.

![Untitled](Images/ProbabilityandStatistics/Untitled%20431.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20432.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20433.png)

## Test For Proportions

![Untitled](Images/ProbabilityandStatistics/Untitled%20434.png)

## Two Sample T-Test

- How to apply **hypothesis testing** to different **samples** in **different populations**?
    - Our goal is to determine if the **population mean** from the US is different than the **population mean** from Argentina.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20435.png)
    
    - Just as with **sample tests**, you can define **three types** of **hypothesis**. In all three cases, you will consider the **null hypothesis** that both **population means** are the same.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20436.png)
    
    - The difference between both **sample means** follows a **Gaussian distribution** Since it's a **linear combination** of **Gaussian** variables.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20437.png)
    
    - You can **standardize** the difference between $\bar X$ and $\bar Y$ to get a **statistic** that has a **standard normal distribution**. However, since we don't know the **population standard deviation** from any of the two groups, then the best we can do is to replace $\sigma$  with the **sample standard deviation** from each group.
    - This statistic has a **t-distribution** because it corresponds to a statistic for the mean of a Gaussian population with an unknown Sigma.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20438.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20439.png)
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20440.png)
    

## Two Sample Test for Proportions

![Untitled](Images/ProbabilityandStatistics/Untitled%20441.png)

## Paired T-Test

- There's another situation where you also have two groups, but they are **not independent**. Imagine you want to test the effectiveness of a training plan to lose weight. The first group will be the people before the training program. The second group is after the training program.
- In this case, you say that the samples are **paired.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20442.png)

- In order to determine if the training program was good for weight loss. You can do that by studying the **mean difference** between **each** member of the group.
- The **sample mean** of these variables is going to be called $\bar D$.

![Untitled](Images/ProbabilityandStatistics/Untitled%20443.png)

![Untitled](Images/ProbabilityandStatistics/Untitled%20444.png)

- Whether you want to consider a **right, left or two-tailed tests**, your **null hypothesis** will always be that there is no weight difference between the groups so replacing $\mu_d$ by **zero.**

![Untitled](Images/ProbabilityandStatistics/Untitled%20445.png)

- Since the **p-value** is **smaller** than the **significance level** of 0.05 then the decision is to **reject** the **null hypothesis** and accept that the population mean for the difference in weight is positive.
- That means that the training program is good for losing weight.

![Untitled](Images/ProbabilityandStatistics/Untitled%20446.png)

## ML Application A/B Testing

- **A/B Testing** is an application of two sample testing.
- Let’s say you have a website with a particular conversion rate and you improved the website and you want to see if the conversion rate went up or down. For this we use **A/B Testing.**
- How **A/B Testing** works?
    - Suppose a company has a web page and it wants to test two different placings for the buy now button. Let's call each of these strategies **A** and **B** and our goal is to determine if switching to strategy **B** leads to higher purchase amounts.
    - To do this we select a group of people. As customers come in they are randomly assigned to design **A** or design **B**.
    - The common rule of **A/B testing** is to send a smaller proportion of customers to the new design because you don't know how good it will be.
    - After designing the experiment and gathering the data, We can use the tests to make a decision.
    - The **null hypothesis** would be that the **mean** purchase with **option A** and the **mean** for **option B** are the **same**, while the **alternative hypothesis** is that the **mean purchase** for strategy **B** is **larger** than the one for strategy **A**. This **hypothesis** can also be written in terms of the **difference** of **means**.
    - We will set **alpha** equals **0.05.**
    - Suppose **purchase amounts** follow a **gaussian distribution** or the **sample** is **big** enough. In that case, We can make our decision using a **two sample t-test**.
    - Notice that if $H_0$  is **true**, then according to the **t-test**, the **statistic** follows a **t-distribution**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20447.png)
    
- What is the difference between **A/B Testing** and **t-tests**?
    - **A/B testing** is broader than just **T-tests**.
    - **A/B Testing** is a methodology for comparing two variations, While the **T-tests** are a statistical tool, **A/B testing** encompasses many more steps.
    - Determining metrics to means, are you interested in mean behavior, in proportions, dispersion, etc.
    - In the previous example we used the **T-test** because we were comparing **means** for **Gaussian populations**. If that were not the case you would use another **statistical test** to make the decision.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20448.png)
    
- How to apply **A/B Testing** if the metric is **proportion**?
    - We’re interested in knowing if **B** has a higher conversion rate than **A**, which is simply the **proportion** of visitors that actually make a purchase.
    - In our case, The variables follow a **binomial distributions**.
    
    ![Untitled](Images/ProbabilityandStatistics/Untitled%20449.png)
    
    - What is the **test statistic** we can use in this case?
        - Since X and Y can be seen as a sum of $n_A$ and $n_B$ **Bernoulli variables** each and the **mean** of a **Bernoulli variable** is the **probability** of **success P.**
        - This means that by the **law** of **large numbers** $\frac X {n_A}$ is similar to $P_A$ as the number of samples gets bigger and the same happens for $\frac Y {n_B}$.
        - By the **central limit theorem** these quotients have a **normal distribution**.
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%20450.png)
        
        - The Difference between these two will make a good approximation for $P_A - P_B$, Which will also be **Gaussian**.
        - A very common way to express this is by **standardizing** the **distribution**.
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%20451.png)
        
        - If $H_0$ is **true**, then $P_A$  equals $P_B$, which you can directly call **P**. So you can replace $P_A$  and $P_B$  by **P** in these statistics. After that, We can rewrite the expression into something nicer.
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%20452.png)
        
        - Since we don’t know the value of **P,** We will replace it by estimation $\hat P$ , by replacing these terms this will give us the **test statistic.**
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%20453.png)
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%20454.png)
        
        ![Untitled](Images/ProbabilityandStatistics/Untitled%20455.png)